# 1-2: Feature Engineering + Baseline - ì™„ì „í•œ êµ¬í˜„ ìƒì„¸

> ë…¸íŠ¸ë¶ + src ëª¨ë“ˆ ìƒì„±ì„ ìœ„í•œ ì™„ì „í•œ ì½”ë“œ

---

## ë©”íƒ€ ì •ë³´

- **íŒŒì¼ëª…**: `notebooks/phase1/1-2_feature_baseline.ipynb`
- **ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„
- **ì…ë ¥ ë°ì´í„°**: `data/processed/train.csv`, `test.csv`
- **ì‚°ì¶œë¬¼**: 
  - `src/ml/feature_engineering.py`
  - `models/baseline_rf.pkl`

---

## ë…¸íŠ¸ë¶ ì…€ êµ¬ì¡°

### [ë§ˆí¬ë‹¤ìš´] ì…€ 1: ì œëª©

```markdown
# 1-2: Feature Engineering + Baseline

## í•™ìŠµ ëª©í‘œ
1. FDSìš© í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒ¨í„´ í•™ìŠµ
2. ì‹œê°„/ê¸ˆì•¡/ì§‘ê³„/ë²”ì£¼í˜• í”¼ì²˜ ìƒì„±
3. Baseline ëª¨ë¸ë¡œ ì„±ëŠ¥ ê¸°ì¤€ì„  í™•ë¦½
4. ê²€ì¦ëœ ì½”ë“œë¥¼ src/ë¡œ ëª¨ë“ˆí™”

## í•µì‹¬ ê°œë…
- **Feature Engineering**: Raw ë°ì´í„°ë¥¼ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë³€í™˜
- **Data Leakage ë°©ì§€**: ì§‘ê³„ í”¼ì²˜ëŠ” trainìœ¼ë¡œë§Œ ê³„ì‚° í›„ testì— ì ìš©
- **Baseline**: ë³µì¡í•œ íŠœë‹ ì „ì— ê¸°ì¤€ ì„±ëŠ¥ í™•ë¦½
```

---

### [ì½”ë“œ] ì…€ 2: íŒ¨í‚¤ì§€ ì„í¬íŠ¸

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

print("âœ… íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ")
```

---

### [ì½”ë“œ] ì…€ 3: ë°ì´í„° ë¡œë“œ

```python
# 1-1ì—ì„œ ì €ì¥í•œ ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv('../data/processed/train.csv')
test_df = pd.read_csv('../data/processed/test.csv')

print(f"Train: {train_df.shape}")
print(f"Test: {test_df.shape}")
print(f"Train ì‚¬ê¸°ìœ¨: {train_df['isFraud'].mean():.2%}")
print(f"Test ì‚¬ê¸°ìœ¨: {test_df['isFraud'].mean():.2%}")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 4: ì‹œê°„ í”¼ì²˜ ì„¤ëª…

```markdown
## 1. ì‹œê°„ í”¼ì²˜ (Time Features)

### ì™œ í•„ìš”í•œê°€?
- ì‚¬ê¸°ëŠ” íŠ¹ì • ì‹œê°„ëŒ€ì— ë§ì´ ë°œìƒ (ì•¼ê°„, ìƒˆë²½)
- ìš”ì¼ë³„ íŒ¨í„´ ì¡´ì¬ (ì£¼ë§ vs í‰ì¼)

### ìƒì„±í•  í”¼ì²˜
| í”¼ì²˜ | ì„¤ëª… | ê³„ì‚° |
|------|------|------|
| hour | ì‹œê°„ (0-23) | (TransactionDT // 3600) % 24 |
| dayofweek | ìš”ì¼ (0-6) | (TransactionDT // 86400) % 7 |
| is_weekend | ì£¼ë§ ì—¬ë¶€ | dayofweek >= 5 |
| is_night | ì•¼ê°„ ì—¬ë¶€ | hour in [22,23,0,1,2,3,4,5] |
```

---

### [ì½”ë“œ] ì…€ 5: ì‹œê°„ í”¼ì²˜ ì˜ˆì œ

```python
# ğŸ“š ì‹œê°„ í”¼ì²˜ ì˜ˆì œ
sample = train_df[['TransactionDT']].head(5).copy()

# TransactionDTëŠ” ì²« ê±°ë˜ ì´í›„ ê²½ê³¼ ì‹œê°„ (ì´ˆ)
sample['hour'] = (sample['TransactionDT'] // 3600) % 24
sample['dayofweek'] = (sample['TransactionDT'] // 86400) % 7

print(sample)
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 6: ì‹¤ìŠµ 1 ì„¤ëª…

```markdown
## ğŸ’» ì‹¤ìŠµ 1: ì‹œê°„ í”¼ì²˜ í•¨ìˆ˜ ì‘ì„±

`create_time_features(df)` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- hour, dayofweek, is_weekend, is_night í”¼ì²˜ ìƒì„±
- ì›ë³¸ dfë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë³µì‚¬ë³¸ ë°˜í™˜
```

---

### [ì½”ë“œ] ì…€ 7: ì‹¤ìŠµ 1 - TODO

```python
# ğŸ’» ì‹¤ìŠµ 1: ì‹œê°„ í”¼ì²˜ í•¨ìˆ˜
def create_time_features(df):
    """
    ì‹œê°„ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    
    Args:
        df: TransactionDT ì»¬ëŸ¼ì´ ìˆëŠ” DataFrame
    
    Returns:
        ì‹œê°„ í”¼ì²˜ê°€ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()
    
    # TODO: hour (0-23)
    df['hour'] = None
    
    # TODO: dayofweek (0-6, 0=ì›”ìš”ì¼)
    df['dayofweek'] = None
    
    # TODO: is_weekend (í† =5, ì¼=6)
    df['is_weekend'] = None
    
    # TODO: is_night (22-6ì‹œ)
    df['is_night'] = None
    
    return df

# í…ŒìŠ¤íŠ¸
# test_result = create_time_features(train_df.head())
# print(test_result[['TransactionDT', 'hour', 'dayofweek', 'is_weekend', 'is_night']])
```

---

### [ì½”ë“œ] ì…€ 8: ì‹¤ìŠµ 1 - ì •ë‹µ

```python
# âœ… ì‹¤ìŠµ 1 ì •ë‹µ
def create_time_features(df):
    """
    ì‹œê°„ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    # hour (0-23)
    df['hour'] = (df['TransactionDT'] // 3600) % 24
    
    # dayofweek (0-6)
    df['dayofweek'] = (df['TransactionDT'] // 86400) % 7
    
    # is_weekend
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    
    # is_night (22, 23, 0, 1, 2, 3, 4, 5)
    df['is_night'] = df['hour'].isin([22, 23, 0, 1, 2, 3, 4, 5]).astype(int)
    
    return df

# ì ìš©
train_df = create_time_features(train_df)
test_df = create_time_features(test_df)

print("ì‹œê°„ í”¼ì²˜ ìƒì„± ì™„ë£Œ!")
print(train_df[['TransactionDT', 'hour', 'dayofweek', 'is_weekend', 'is_night']].head())
```

---

### [ì½”ë“œ] ì…€ 9: ì²´í¬í¬ì¸íŠ¸ 1

```python
# ì²´í¬í¬ì¸íŠ¸ 1
assert 'hour' in train_df.columns, "âŒ hour í”¼ì²˜ ì—†ìŒ"
assert 'dayofweek' in train_df.columns, "âŒ dayofweek í”¼ì²˜ ì—†ìŒ"
assert 'is_weekend' in train_df.columns, "âŒ is_weekend í”¼ì²˜ ì—†ìŒ"
assert 'is_night' in train_df.columns, "âŒ is_night í”¼ì²˜ ì—†ìŒ"

assert train_df['hour'].min() >= 0 and train_df['hour'].max() <= 23, "âŒ hour ë²”ìœ„ ì˜¤ë¥˜"
assert train_df['dayofweek'].min() >= 0 and train_df['dayofweek'].max() <= 6, "âŒ dayofweek ë²”ìœ„ ì˜¤ë¥˜"
assert set(train_df['is_weekend'].unique()).issubset({0, 1}), "âŒ is_weekendëŠ” 0,1ë§Œ"
assert set(train_df['is_night'].unique()).issubset({0, 1}), "âŒ is_nightëŠ” 0,1ë§Œ"

print("âœ… ì²´í¬í¬ì¸íŠ¸ 1 í†µê³¼!")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 10: ê¸ˆì•¡ í”¼ì²˜ ì„¤ëª…

```markdown
## 2. ê¸ˆì•¡ í”¼ì²˜ (Amount Features)

### ì™œ í•„ìš”í•œê°€?
- ê¸ˆì•¡ ë¶„í¬ê°€ ì‹¬í•˜ê²Œ skewed (ëŒ€ë¶€ë¶„ ì†Œì•¡, ì¼ë¶€ ê³ ì•¡)
- ë¡œê·¸ ë³€í™˜ìœ¼ë¡œ ì •ê·œí™”
- ì‚¬ê¸°ëŠ” "ë”± ë–¨ì–´ì§€ëŠ” ê¸ˆì•¡"ì´ ë§ìŒ (100, 500 ë“±)

### ìƒì„±í•  í”¼ì²˜
| í”¼ì²˜ | ì„¤ëª… |
|------|------|
| amt_log | log(1 + amount) |
| amt_decimal | ì†Œìˆ˜ì  ìœ ë¬´ (0 or 1) |
| amt_bin | ê¸ˆì•¡ êµ¬ê°„ (0: ~50, 1: ~200, 2: ~500, 3: 500+) |
```

---

### [ì½”ë“œ] ì…€ 11: ì‹¤ìŠµ 2 - TODO

```python
# ğŸ’» ì‹¤ìŠµ 2: ê¸ˆì•¡ í”¼ì²˜ í•¨ìˆ˜
def create_amount_features(df):
    """
    ê¸ˆì•¡ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    # TODO: ë¡œê·¸ ë³€í™˜ (np.log1p ì‚¬ìš©)
    df['amt_log'] = None
    
    # TODO: ì†Œìˆ˜ì  ìœ ë¬´ (amount % 1 != 0ì´ë©´ ì†Œìˆ˜ì  ìˆìŒ)
    df['amt_decimal'] = None
    
    # TODO: ê¸ˆì•¡ êµ¬ê°„í™”
    # 0: $0-50, 1: $50-200, 2: $200-500, 3: $500+
    # íŒíŠ¸: pd.cut(df['TransactionAmt'], bins=[0, 50, 200, 500, np.inf], labels=[0,1,2,3])
    df['amt_bin'] = None
    
    return df
```

---

### [ì½”ë“œ] ì…€ 12: ì‹¤ìŠµ 2 - ì •ë‹µ

```python
# âœ… ì‹¤ìŠµ 2 ì •ë‹µ
def create_amount_features(df):
    """
    ê¸ˆì•¡ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    # ë¡œê·¸ ë³€í™˜
    df['amt_log'] = np.log1p(df['TransactionAmt'])
    
    # ì†Œìˆ˜ì  ìœ ë¬´
    df['amt_decimal'] = (df['TransactionAmt'] % 1 != 0).astype(int)
    
    # ê¸ˆì•¡ êµ¬ê°„í™”
    df['amt_bin'] = pd.cut(
        df['TransactionAmt'], 
        bins=[0, 50, 200, 500, np.inf], 
        labels=[0, 1, 2, 3]
    ).astype(int)
    
    return df

# ì ìš©
train_df = create_amount_features(train_df)
test_df = create_amount_features(test_df)

print("ê¸ˆì•¡ í”¼ì²˜ ìƒì„± ì™„ë£Œ!")
print(train_df[['TransactionAmt', 'amt_log', 'amt_decimal', 'amt_bin']].head(10))
```

---

### [ì½”ë“œ] ì…€ 13: ì²´í¬í¬ì¸íŠ¸ 2

```python
# ì²´í¬í¬ì¸íŠ¸ 2
assert 'amt_log' in train_df.columns, "âŒ amt_log ì—†ìŒ"
assert 'amt_decimal' in train_df.columns, "âŒ amt_decimal ì—†ìŒ"
assert 'amt_bin' in train_df.columns, "âŒ amt_bin ì—†ìŒ"

assert train_df['amt_log'].min() >= 0, "âŒ log1pëŠ” í•­ìƒ >= 0"
assert set(train_df['amt_decimal'].unique()).issubset({0, 1}), "âŒ amt_decimalì€ 0,1ë§Œ"

print("âœ… ì²´í¬í¬ì¸íŠ¸ 2 í†µê³¼!")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 14: ì§‘ê³„ í”¼ì²˜ ì„¤ëª…

```markdown
## 3. ì§‘ê³„ í”¼ì²˜ (Aggregation Features)

### ì™œ í•„ìš”í•œê°€?
- ì¹´ë“œë³„ ê±°ë˜ íŒ¨í„´ì´ ì‚¬ê¸° íƒì§€ì— ì¤‘ìš”
- "ì´ ì¹´ë“œëŠ” í‰ì†Œ ì–¼ë§ˆë‚˜ ìì£¼, ì–¼ë§ˆì”© ì“°ëŠ”ê°€?"

### âš ï¸ Data Leakage ì£¼ì˜!
```
âŒ ì˜ëª»ëœ ë°©ë²•: ì „ì²´ ë°ì´í„°ë¡œ ì§‘ê³„ â†’ train/testì— ì ìš©
âœ… ì˜¬ë°”ë¥¸ ë°©ë²•: trainìœ¼ë¡œë§Œ ì§‘ê³„ â†’ testì— merge
```

### ìƒì„±í•  í”¼ì²˜
| í”¼ì²˜ | ì„¤ëª… |
|------|------|
| card1_count | card1ë³„ ê±°ë˜ íšŸìˆ˜ |
| card1_amt_mean | card1ë³„ í‰ê·  ê¸ˆì•¡ |
| card1_amt_std | card1ë³„ ê¸ˆì•¡ í‘œì¤€í¸ì°¨ |
```

---

### [ì½”ë“œ] ì…€ 15: ì‹¤ìŠµ 3 - TODO

```python
# ğŸ’» ì‹¤ìŠµ 3: ì§‘ê³„ í”¼ì²˜ í•¨ìˆ˜
def create_agg_features(train_df, test_df, group_col='card1'):
    """
    ì§‘ê³„ í”¼ì²˜ ìƒì„± (Data Leakage ë°©ì§€)
    
    Args:
        train_df: í•™ìŠµ ë°ì´í„°
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°
        group_col: ê·¸ë£¹í•‘ ê¸°ì¤€ ì»¬ëŸ¼
    
    Returns:
        train_df, test_df (ì§‘ê³„ í”¼ì²˜ ì¶”ê°€ë¨)
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    
    # TODO: trainì—ì„œ ì§‘ê³„ ê³„ì‚°
    # íŒíŠ¸: train_df.groupby(group_col)['TransactionAmt'].agg(['count', 'mean', 'std'])
    agg_df = None
    
    # TODO: ì»¬ëŸ¼ëª… ë³€ê²½
    # agg_df.columns = [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']
    
    # TODO: trainì— merge
    # train_df = pd.merge(train_df, agg_df, on=group_col, how='left')
    
    # TODO: testì— merge (train ì§‘ê³„ê°’ ì‚¬ìš©!)
    # test_df = pd.merge(test_df, agg_df, on=group_col, how='left')
    
    return train_df, test_df
```

---

### [ì½”ë“œ] ì…€ 16: ì‹¤ìŠµ 3 - ì •ë‹µ

```python
# âœ… ì‹¤ìŠµ 3 ì •ë‹µ
def create_agg_features(train_df, test_df, group_col='card1'):
    """
    ì§‘ê³„ í”¼ì²˜ ìƒì„± (Data Leakage ë°©ì§€)
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    
    # trainì—ì„œë§Œ ì§‘ê³„ ê³„ì‚°
    agg_df = train_df.groupby(group_col)['TransactionAmt'].agg(['count', 'mean', 'std'])
    agg_df.columns = [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']
    agg_df = agg_df.reset_index()
    
    # ê²°ì¸¡ ì²˜ë¦¬ (stdëŠ” ê±°ë˜ 1ê±´ì´ë©´ NaN)
    agg_df[f'{group_col}_amt_std'] = agg_df[f'{group_col}_amt_std'].fillna(0)
    
    # trainì— merge
    train_df = pd.merge(train_df, agg_df, on=group_col, how='left')
    
    # testì— merge (train ì§‘ê³„ê°’ ì‚¬ìš©!)
    test_df = pd.merge(test_df, agg_df, on=group_col, how='left')
    
    # testì—ë§Œ ìˆëŠ” card1ì€ NaN â†’ ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    for col in [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']:
        fill_value = train_df[col].mean()
        test_df[col] = test_df[col].fillna(fill_value)
    
    return train_df, test_df

# ì ìš©
train_df, test_df = create_agg_features(train_df, test_df, 'card1')

print("ì§‘ê³„ í”¼ì²˜ ìƒì„± ì™„ë£Œ!")
print(train_df[['card1', 'card1_count', 'card1_amt_mean', 'card1_amt_std']].head())
```

---

### [ì½”ë“œ] ì…€ 17: ì²´í¬í¬ì¸íŠ¸ 3

```python
# ì²´í¬í¬ì¸íŠ¸ 3
assert 'card1_count' in train_df.columns, "âŒ card1_count ì—†ìŒ"
assert 'card1_amt_mean' in train_df.columns, "âŒ card1_amt_mean ì—†ìŒ"
assert 'card1_amt_std' in train_df.columns, "âŒ card1_amt_std ì—†ìŒ"

# testì—ë„ ìˆëŠ”ì§€ í™•ì¸
assert 'card1_count' in test_df.columns, "âŒ testì— card1_count ì—†ìŒ"

# ê²°ì¸¡ í™•ì¸
assert train_df['card1_count'].isna().sum() == 0, "âŒ trainì— ê²°ì¸¡ ìˆìŒ"
assert test_df['card1_count'].isna().sum() == 0, "âŒ testì— ê²°ì¸¡ ìˆìŒ"

print("âœ… ì²´í¬í¬ì¸íŠ¸ 3 í†µê³¼!")
print("   â†’ Data Leakage ë°©ì§€: train ì§‘ê³„ê°’ì„ testì— ì ìš©")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 18: ë²”ì£¼í˜• ì¸ì½”ë”© ì„¤ëª…

```markdown
## 4. ë²”ì£¼í˜• ì¸ì½”ë”© (Categorical Encoding)

### Label Encoding
- ë¬¸ìì—´ â†’ ìˆ«ìë¡œ ë³€í™˜
- íŠ¸ë¦¬ ëª¨ë¸ì—ì„œ ì˜ ì‘ë™
- NaNì€ 'unknown'ìœ¼ë¡œ ì²˜ë¦¬

### ì¸ì½”ë”©í•  ì»¬ëŸ¼
- ProductCD: ìƒí’ˆ ì¢…ë¥˜
- card4: ì¹´ë“œ ì¢…ë¥˜ (visa, mastercard ë“±)
- card6: ì¹´ë“œ íƒ€ì… (debit, credit ë“±)
- P_emaildomain: êµ¬ë§¤ì ì´ë©”ì¼ ë„ë©”ì¸
```

---

### [ì½”ë“œ] ì…€ 19: ì‹¤ìŠµ 4 - TODO

```python
# ğŸ’» ì‹¤ìŠµ 4: ë²”ì£¼í˜• ì¸ì½”ë”© í•¨ìˆ˜
def encode_categorical(train_df, test_df, cat_cols):
    """
    ë²”ì£¼í˜• ì»¬ëŸ¼ Label Encoding
    
    Args:
        train_df, test_df: ë°ì´í„°í”„ë ˆì„
        cat_cols: ì¸ì½”ë”©í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        train_df, test_df, encoders (ë”•ì…”ë„ˆë¦¬)
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    encoders = {}
    
    for col in cat_cols:
        if col not in train_df.columns:
            continue
            
        le = LabelEncoder()
        
        # TODO: NaNì„ 'unknown'ìœ¼ë¡œ ì±„ìš°ê¸°
        # train_df[col] = train_df[col].fillna('unknown').astype(str)
        # test_df[col] = test_df[col].fillna('unknown').astype(str)
        
        # TODO: trainì—ì„œ fit
        # le.fit(train_df[col])
        
        # TODO: train, testì— transform
        # train_df[col] = le.transform(train_df[col])
        # test_df[col] = ... (testì— ìƒˆë¡œìš´ ê°’ ìˆìœ¼ë©´ ì²˜ë¦¬ í•„ìš”)
        
        # encoders[col] = le
        pass
    
    return train_df, test_df, encoders
```

---

### [ì½”ë“œ] ì…€ 20: ì‹¤ìŠµ 4 - ì •ë‹µ

```python
# âœ… ì‹¤ìŠµ 4 ì •ë‹µ
def encode_categorical(train_df, test_df, cat_cols):
    """
    ë²”ì£¼í˜• ì»¬ëŸ¼ Label Encoding
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    encoders = {}
    
    for col in cat_cols:
        if col not in train_df.columns:
            print(f"âš ï¸ {col} ì»¬ëŸ¼ ì—†ìŒ, ìŠ¤í‚µ")
            continue
        
        le = LabelEncoder()
        
        # NaN â†’ 'unknown'
        train_df[col] = train_df[col].fillna('unknown').astype(str)
        test_df[col] = test_df[col].fillna('unknown').astype(str)
        
        # train + test í•©ì³ì„œ fit (testì—ë§Œ ìˆëŠ” ê°’ ì²˜ë¦¬)
        all_values = pd.concat([train_df[col], test_df[col]]).unique()
        le.fit(all_values)
        
        # transform
        train_df[col] = le.transform(train_df[col])
        test_df[col] = le.transform(test_df[col])
        
        encoders[col] = le
        print(f"âœ… {col}: {len(le.classes_)}ê°œ í´ë˜ìŠ¤")
    
    return train_df, test_df, encoders

# ì ìš©
cat_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain']
train_df, test_df, encoders = encode_categorical(train_df, test_df, cat_cols)

print("\në²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ!")
```

---

### [ì½”ë“œ] ì…€ 21: ì²´í¬í¬ì¸íŠ¸ 4

```python
# ì²´í¬í¬ì¸íŠ¸ 4
for col in ['ProductCD', 'card4', 'card6']:
    if col in train_df.columns:
        assert train_df[col].dtype in ['int64', 'int32'], f"âŒ {col} ì¸ì½”ë”© ì•ˆë¨"

assert len(encoders) > 0, "âŒ ì¸ì½”ë”ê°€ ì—†ìŒ"

print("âœ… ì²´í¬í¬ì¸íŠ¸ 4 í†µê³¼!")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 22: Baseline ëª¨ë¸ ì„¤ëª…

```markdown
## 5. Baseline ëª¨ë¸

### ì™œ Baselineì´ í•„ìš”í•œê°€?
- ë³µì¡í•œ íŠœë‹ ì „ì— ê¸°ì¤€ ì„±ëŠ¥ í™•ë¦½
- "ìµœì†Œí•œ ì´ ì •ë„ëŠ” ë‚˜ì™€ì•¼ í•œë‹¤"
- RandomForest: ë¹ ë¥´ê³  ì•ˆì •ì 

### í‰ê°€ ì§€í‘œ
- **AUC-ROC**: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ì£¼ìš” ì§€í‘œ
- (AccuracyëŠ” ì˜ë¯¸ ì—†ìŒ)
```

---

### [ì½”ë“œ] ì…€ 23: í”¼ì²˜ ì„ íƒ

```python
# í”¼ì²˜ ì„ íƒ
feature_cols = [
    # ì‹œê°„ í”¼ì²˜
    'hour', 'dayofweek', 'is_weekend', 'is_night',
    # ê¸ˆì•¡ í”¼ì²˜
    'TransactionAmt', 'amt_log', 'amt_decimal', 'amt_bin',
    # ì§‘ê³„ í”¼ì²˜
    'card1_count', 'card1_amt_mean', 'card1_amt_std',
    # ë²”ì£¼í˜• (ì¸ì½”ë”©ë¨)
    'ProductCD', 'card4', 'card6',
    # ê¸°íƒ€ ìˆ˜ì¹˜í˜•
    'card1', 'card2', 'card3', 'card5',
]

# ì‹¤ì œ ìˆëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
feature_cols = [col for col in feature_cols if col in train_df.columns]
print(f"ì„ íƒëœ í”¼ì²˜: {len(feature_cols)}ê°œ")
print(feature_cols)
```

---

### [ì½”ë“œ] ì…€ 24: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„

```python
# X, y ë¶„ë¦¬
X_train = train_df[feature_cols].copy()
y_train = train_df['isFraud'].copy()

X_test = test_df[feature_cols].copy()
y_test = test_df['isFraud'].copy()

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (íŠ¸ë¦¬ ëª¨ë¸ìš© -999)
X_train = X_train.fillna(-999)
X_test = X_test.fillna(-999)

print(f"X_train: {X_train.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train ì‚¬ê¸°ìœ¨: {y_train.mean():.2%}")
print(f"y_test ì‚¬ê¸°ìœ¨: {y_test.mean():.2%}")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 25: ì‹¤ìŠµ 5 ì„¤ëª…

```markdown
## ğŸ’» ì‹¤ìŠµ 5: Baseline ëª¨ë¸ í•™ìŠµ

RandomForestClassifierë¡œ Baseline ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.

**ìš”êµ¬ì‚¬í•­:**
1. RandomForest ëª¨ë¸ ìƒì„± (n_estimators=100, random_state=42)
2. í•™ìŠµ ë° ì˜ˆì¸¡
3. AUC-ROC ê³„ì‚°
```

---

### [ì½”ë“œ] ì…€ 26: ì‹¤ìŠµ 5 - TODO

```python
# ğŸ’» ì‹¤ìŠµ 5: Baseline RandomForest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

# TODO: ëª¨ë¸ ìƒì„±
# rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)

# TODO: í•™ìŠµ
# rf_model.fit(X_train, y_train)

# TODO: í™•ë¥  ì˜ˆì¸¡
# y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

# TODO: AUC ê³„ì‚°
# auc_score = roc_auc_score(y_test, y_pred_proba)
# print(f"Baseline AUC: {auc_score:.4f}")
```

---

### [ì½”ë“œ] ì…€ 27: ì‹¤ìŠµ 5 - ì •ë‹µ

```python
# âœ… ì‹¤ìŠµ 5 ì •ë‹µ
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

# ëª¨ë¸ ìƒì„±
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=10,
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'  # ë¶ˆê· í˜• ì²˜ë¦¬
)

# í•™ìŠµ
print("í•™ìŠµ ì¤‘...")
rf_model.fit(X_train, y_train)
print("í•™ìŠµ ì™„ë£Œ!")

# ì˜ˆì¸¡
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

# AUC
auc_score = roc_auc_score(y_test, y_pred_proba)
print(f"\nğŸ¯ Baseline AUC: {auc_score:.4f}")
```

---

### [ì½”ë“œ] ì…€ 28: ì²´í¬í¬ì¸íŠ¸ 5

```python
# ì²´í¬í¬ì¸íŠ¸ 5
assert auc_score > 0.7, "âŒ AUCê°€ 0.7 ì´ìƒì´ì–´ì•¼ í•¨"

print("âœ… ì²´í¬í¬ì¸íŠ¸ 5 í†µê³¼!")
print(f"   Baseline AUC: {auc_score:.4f}")
print("   â†’ 1-3ì—ì„œ XGBoostë¡œ ê°œì„  ì˜ˆì •")
```

---

### [ì½”ë“œ] ì…€ 29: í”¼ì²˜ ì¤‘ìš”ë„

```python
# í”¼ì²˜ ì¤‘ìš”ë„
import matplotlib.pyplot as plt

importance_df = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

# ìƒìœ„ 15ê°œ ì‹œê°í™”
fig, ax = plt.subplots(figsize=(10, 6))
top_features = importance_df.head(15)
ax.barh(top_features['feature'], top_features['importance'], color='steelblue')
ax.set_xlabel('Importance')
ax.set_title('Top 15 Feature Importance (RandomForest)')
ax.invert_yaxis()

plt.tight_layout()
plt.show()

print("=== Top 10 í”¼ì²˜ ===")
print(importance_df.head(10).to_string(index=False))
```

---

### [ì½”ë“œ] ì…€ 30: ëª¨ë¸ ì €ì¥

```python
# ëª¨ë¸ ì €ì¥
os.makedirs('../models', exist_ok=True)

# ëª¨ë¸ ì €ì¥
joblib.dump(rf_model, '../models/baseline_rf.pkl')

# ë©”íƒ€ë°ì´í„° ì €ì¥
metadata = {
    'feature_cols': feature_cols,
    'auc_score': auc_score,
    'model_type': 'RandomForestClassifier'
}
joblib.dump(metadata, '../models/baseline_rf_metadata.pkl')

# ì¸ì½”ë” ì €ì¥
joblib.dump(encoders, '../models/label_encoders.pkl')

print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
print("   - models/baseline_rf.pkl")
print("   - models/baseline_rf_metadata.pkl")
print("   - models/label_encoders.pkl")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 31: ëª¨ë“ˆí™”

```markdown
## 6. ì½”ë“œ ëª¨ë“ˆí™”

ê²€ì¦ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì½”ë“œë¥¼ `src/ml/feature_engineering.py`ë¡œ ëª¨ë“ˆí™”í•©ë‹ˆë‹¤.

ì´í›„ ë…¸íŠ¸ë¶ì—ì„œ:
```python
from src.ml.feature_engineering import create_time_features, create_amount_features
```
```

---

### [ì½”ë“œ] ì…€ 32: ëª¨ë“ˆ íŒŒì¼ ìƒì„±

```python
# src/ml/feature_engineering.py ìƒì„±
module_code = '''"""
Feature Engineering for FDS
"""
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder


def create_time_features(df):
    """
    ì‹œê°„ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    
    Args:
        df: TransactionDT ì»¬ëŸ¼ì´ ìˆëŠ” DataFrame
    
    Returns:
        ì‹œê°„ í”¼ì²˜ê°€ ì¶”ê°€ëœ DataFrame
    """
    df = df.copy()
    
    df['hour'] = (df['TransactionDT'] // 3600) % 24
    df['dayofweek'] = (df['TransactionDT'] // 86400) % 7
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    df['is_night'] = df['hour'].isin([22, 23, 0, 1, 2, 3, 4, 5]).astype(int)
    
    return df


def create_amount_features(df):
    """
    ê¸ˆì•¡ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    df['amt_log'] = np.log1p(df['TransactionAmt'])
    df['amt_decimal'] = (df['TransactionAmt'] % 1 != 0).astype(int)
    df['amt_bin'] = pd.cut(
        df['TransactionAmt'], 
        bins=[0, 50, 200, 500, np.inf], 
        labels=[0, 1, 2, 3]
    ).astype(int)
    
    return df


def create_agg_features(train_df, test_df, group_col='card1'):
    """
    ì§‘ê³„ í”¼ì²˜ ìƒì„± (Data Leakage ë°©ì§€)
    
    Args:
        train_df: í•™ìŠµ ë°ì´í„° (ì§‘ê³„ ê³„ì‚°ìš©)
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì§‘ê³„ê°’ ì ìš©)
        group_col: ê·¸ë£¹í•‘ ê¸°ì¤€ ì»¬ëŸ¼
    
    Returns:
        train_df, test_df (ì§‘ê³„ í”¼ì²˜ ì¶”ê°€ë¨)
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    
    # trainì—ì„œë§Œ ì§‘ê³„ ê³„ì‚°
    agg_df = train_df.groupby(group_col)['TransactionAmt'].agg(['count', 'mean', 'std'])
    agg_df.columns = [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']
    agg_df = agg_df.reset_index()
    agg_df[f'{group_col}_amt_std'] = agg_df[f'{group_col}_amt_std'].fillna(0)
    
    # merge
    train_df = pd.merge(train_df, agg_df, on=group_col, how='left')
    test_df = pd.merge(test_df, agg_df, on=group_col, how='left')
    
    # test ê²°ì¸¡ ì²˜ë¦¬
    for col in [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']:
        fill_value = train_df[col].mean()
        test_df[col] = test_df[col].fillna(fill_value)
    
    return train_df, test_df


def encode_categorical(train_df, test_df, cat_cols):
    """
    ë²”ì£¼í˜• ì»¬ëŸ¼ Label Encoding
    
    Args:
        train_df, test_df: ë°ì´í„°í”„ë ˆì„
        cat_cols: ì¸ì½”ë”©í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        train_df, test_df, encoders (ë”•ì…”ë„ˆë¦¬)
    """
    train_df = train_df.copy()
    test_df = test_df.copy()
    encoders = {}
    
    for col in cat_cols:
        if col not in train_df.columns:
            continue
        
        le = LabelEncoder()
        
        train_df[col] = train_df[col].fillna('unknown').astype(str)
        test_df[col] = test_df[col].fillna('unknown').astype(str)
        
        all_values = pd.concat([train_df[col], test_df[col]]).unique()
        le.fit(all_values)
        
        train_df[col] = le.transform(train_df[col])
        test_df[col] = le.transform(test_df[col])
        
        encoders[col] = le
    
    return train_df, test_df, encoders


def prepare_features(train_df, test_df, cat_cols=None):
    """
    ì „ì²´ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸
    
    Args:
        train_df, test_df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        cat_cols: ë²”ì£¼í˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        train_df, test_df, encoders
    """
    if cat_cols is None:
        cat_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain']
    
    # ì‹œê°„ í”¼ì²˜
    train_df = create_time_features(train_df)
    test_df = create_time_features(test_df)
    
    # ê¸ˆì•¡ í”¼ì²˜
    train_df = create_amount_features(train_df)
    test_df = create_amount_features(test_df)
    
    # ì§‘ê³„ í”¼ì²˜
    train_df, test_df = create_agg_features(train_df, test_df, 'card1')
    
    # ë²”ì£¼í˜• ì¸ì½”ë”©
    train_df, test_df, encoders = encode_categorical(train_df, test_df, cat_cols)
    
    return train_df, test_df, encoders
'''

# íŒŒì¼ ì €ì¥
os.makedirs('../src/ml', exist_ok=True)

# __init__.py ìƒì„±
with open('../src/__init__.py', 'w') as f:
    f.write('')
    
with open('../src/ml/__init__.py', 'w') as f:
    f.write('from .feature_engineering import *\n')

# ëª¨ë“ˆ ì €ì¥
with open('../src/ml/feature_engineering.py', 'w') as f:
    f.write(module_code)

print("âœ… ëª¨ë“ˆ ìƒì„± ì™„ë£Œ!")
print("   - src/ml/__init__.py")
print("   - src/ml/feature_engineering.py")
```

---

### [ì½”ë“œ] ì…€ 33: ëª¨ë“ˆ í…ŒìŠ¤íŠ¸

```python
# ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
import sys
sys.path.append('..')

from src.ml.feature_engineering import create_time_features, prepare_features

# í…ŒìŠ¤íŠ¸
test_data = pd.DataFrame({
    'TransactionDT': [86400, 172800, 259200],
    'TransactionAmt': [100, 200, 300]
})

result = create_time_features(test_data)
print("ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸:")
print(result[['TransactionDT', 'hour', 'dayofweek']])

print("\nâœ… ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
```

---

### [ë§ˆí¬ë‹¤ìš´] ì…€ 34: ìµœì¢… ì²´í¬í¬ì¸íŠ¸

```markdown
## âœ… ìµœì¢… ì²´í¬í¬ì¸íŠ¸
```

---

### [ì½”ë“œ] ì…€ 35: ìµœì¢… ìš”ì•½

```python
print("="*60)
print("ğŸ‰ 1-2 ì™„ë£Œ: Feature Engineering + Baseline")
print("="*60)
print()
print("ğŸ“Š ìƒì„±í•œ í”¼ì²˜:")
print("   - ì‹œê°„: hour, dayofweek, is_weekend, is_night")
print("   - ê¸ˆì•¡: amt_log, amt_decimal, amt_bin")
print("   - ì§‘ê³„: card1_count, card1_amt_mean, card1_amt_std")
print("   - ë²”ì£¼í˜•: ProductCD, card4, card6 (Label Encoded)")
print()
print(f"ğŸ“ˆ Baseline ì„±ëŠ¥:")
print(f"   - ëª¨ë¸: RandomForest")
print(f"   - AUC: {auc_score:.4f}")
print()
print("ğŸ“‚ ì‚°ì¶œë¬¼:")
print("   - src/ml/feature_engineering.py (ëª¨ë“ˆ)")
print("   - models/baseline_rf.pkl")
print("   - models/baseline_rf_metadata.pkl")
print("   - models/label_encoders.pkl")
print()
print("ğŸ¯ ë©´ì ‘ í¬ì¸íŠ¸:")
print("   Q: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì—ì„œ ì£¼ì˜í•  ì ì€?")
print("   A: Data Leakage ë°©ì§€ì…ë‹ˆë‹¤. ì§‘ê³„ í”¼ì²˜ëŠ” trainì—ì„œë§Œ")
print("      ê³„ì‚°í•˜ê³  testì— ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´")
print("      ë¯¸ë˜ ì •ë³´ê°€ ëˆ„ì¶œë˜ì–´ ê³¼ì í•©ë©ë‹ˆë‹¤.")
print()
print("â¡ï¸ ë‹¤ìŒ: 1-3 ëª¨ë¸ ê³ ë„í™” (XGBoost vs LightGBM vs CatBoost)")
```

---

## src/ml/feature_engineering.py (ìµœì¢…ë³¸)

ìœ„ ì…€ 32ì—ì„œ ìƒì„±ë˜ëŠ” ëª¨ë“ˆì˜ ì „ì²´ ì½”ë“œì…ë‹ˆë‹¤.

```python
"""
Feature Engineering for FDS
"""
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder


def create_time_features(df):
    """ì‹œê°„ ê´€ë ¨ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    df['hour'] = (df['TransactionDT'] // 3600) % 24
    df['dayofweek'] = (df['TransactionDT'] // 86400) % 7
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    df['is_night'] = df['hour'].isin([22, 23, 0, 1, 2, 3, 4, 5]).astype(int)
    return df


def create_amount_features(df):
    """ê¸ˆì•¡ ê´€ë ¨ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    df['amt_log'] = np.log1p(df['TransactionAmt'])
    df['amt_decimal'] = (df['TransactionAmt'] % 1 != 0).astype(int)
    df['amt_bin'] = pd.cut(
        df['TransactionAmt'], 
        bins=[0, 50, 200, 500, np.inf], 
        labels=[0, 1, 2, 3]
    ).astype(int)
    return df


def create_agg_features(train_df, test_df, group_col='card1'):
    """ì§‘ê³„ í”¼ì²˜ ìƒì„± (Data Leakage ë°©ì§€)"""
    train_df = train_df.copy()
    test_df = test_df.copy()
    
    agg_df = train_df.groupby(group_col)['TransactionAmt'].agg(['count', 'mean', 'std'])
    agg_df.columns = [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']
    agg_df = agg_df.reset_index()
    agg_df[f'{group_col}_amt_std'] = agg_df[f'{group_col}_amt_std'].fillna(0)
    
    train_df = pd.merge(train_df, agg_df, on=group_col, how='left')
    test_df = pd.merge(test_df, agg_df, on=group_col, how='left')
    
    for col in [f'{group_col}_count', f'{group_col}_amt_mean', f'{group_col}_amt_std']:
        fill_value = train_df[col].mean()
        test_df[col] = test_df[col].fillna(fill_value)
    
    return train_df, test_df


def encode_categorical(train_df, test_df, cat_cols):
    """ë²”ì£¼í˜• ì»¬ëŸ¼ Label Encoding"""
    train_df = train_df.copy()
    test_df = test_df.copy()
    encoders = {}
    
    for col in cat_cols:
        if col not in train_df.columns:
            continue
        
        le = LabelEncoder()
        train_df[col] = train_df[col].fillna('unknown').astype(str)
        test_df[col] = test_df[col].fillna('unknown').astype(str)
        
        all_values = pd.concat([train_df[col], test_df[col]]).unique()
        le.fit(all_values)
        
        train_df[col] = le.transform(train_df[col])
        test_df[col] = le.transform(test_df[col])
        encoders[col] = le
    
    return train_df, test_df, encoders


def prepare_features(train_df, test_df, cat_cols=None):
    """ì „ì²´ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸"""
    if cat_cols is None:
        cat_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain']
    
    train_df = create_time_features(train_df)
    test_df = create_time_features(test_df)
    
    train_df = create_amount_features(train_df)
    test_df = create_amount_features(test_df)
    
    train_df, test_df = create_agg_features(train_df, test_df, 'card1')
    train_df, test_df, encoders = encode_categorical(train_df, test_df, cat_cols)
    
    return train_df, test_df, encoders
```

---

## ì˜ˆìƒ ì‚°ì¶œë¬¼

1. **ë…¸íŠ¸ë¶**: `notebooks/phase1/1-2_feature_baseline.ipynb`
2. **ëª¨ë“ˆ**: `src/ml/feature_engineering.py`
3. **ëª¨ë¸**:
   - `models/baseline_rf.pkl`
   - `models/baseline_rf_metadata.pkl`
   - `models/label_encoders.pkl`
