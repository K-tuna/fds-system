{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-S1: MLflow Tracking 기초\n",
    "\n",
    "MLflow를 사용한 **실험 추적**을 학습합니다.\n",
    "\n",
    "## 학습 목표\n",
    "1. 왜 실험 추적이 필요한가? (Phase 1 문제점 연결)\n",
    "2. MLflow Tracking: Experiment, Run, Artifact\n",
    "3. Autolog로 자동 기록\n",
    "4. Autolog + 수동 로깅 조합 (실무 패턴)\n",
    "\n",
    "## 예상 시간\n",
    "- 약 1시간\n",
    "\n",
    "## 선수 조건\n",
    "- Phase 1 완료 (XGBoost 학습 경험)\n",
    "- `pip install mlflow xgboost scikit-learn`\n",
    "\n",
    "## 다음 학습\n",
    "- 2-S2: Model Registry (버전 관리, Alias, Champion/Challenger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 설치 (필요시)\n",
    "# !pip install mlflow xgboost scikit-learn\n",
    "\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "print(f\"MLflow 버전: {mlflow.__version__}\")\n",
    "print(f\"XGBoost 버전: {xgb.__version__}\")\n",
    "\n",
    "# 전역 autolog 비활성화 (학습 목적으로 수동 로깅부터 배움)\n",
    "mlflow.autolog(disable=True)\n",
    "print(\"\\n전역 autolog 비활성화됨 (학습용)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습용 데이터 생성 (불균형 이진 분류)\n",
    "X, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    weights=[0.95, 0.05],  # 5% 양성 클래스 (사기)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"학습 데이터: {len(X_train)}건\")\n",
    "print(f\"테스트 데이터: {len(X_test)}건\")\n",
    "print(f\"양성 비율: {y_train.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 왜 실험 추적이 필요한가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Phase 1에서 겪은 문제\n",
    "\n",
    "Phase 1에서 XGBoost를 학습할 때 이런 경험 있으셨나요?\n",
    "\n",
    "```\n",
    "[문제 상황]\n",
    "\n",
    "월요일: learning_rate=0.1, max_depth=6 -> AUC 0.85\n",
    "화요일: learning_rate=0.05, max_depth=8 -> AUC 0.87\n",
    "수요일: learning_rate=???, max_depth=??? -> AUC 0.89\n",
    "\n",
    "금요일: \"수요일 모델이 제일 좋았는데, 하이퍼파라미터 뭐였지?\"\n",
    "```\n",
    "\n",
    "**수동 기록의 한계:**\n",
    "- 엑셀/노트에 기록 -> 실수, 누락\n",
    "- 파일명으로 구분 -> `model_v1.pkl`, `model_final.pkl`, `model_final_v2.pkl`\n",
    "- 재현 불가능 -> \"그때 왜 그 결과가 나왔지?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동 기록의 문제점 시뮬레이션\n",
    "\n",
    "# 이렇게 수동으로 기록하면...\n",
    "experiment_log = []\n",
    "\n",
    "# 실험 1\n",
    "experiment_log.append({\n",
    "    'date': '월요일',\n",
    "    'lr': 0.1,\n",
    "    'depth': 6,\n",
    "    'auc': 0.85\n",
    "})\n",
    "\n",
    "# 실험 2\n",
    "experiment_log.append({\n",
    "    'date': '화요일',\n",
    "    'lr': 0.05,\n",
    "    'depth': 8,\n",
    "    'auc': 0.87\n",
    "})\n",
    "\n",
    "# 실험 3 - 실수로 기록 안 함!\n",
    "# experiment_log.append({...})  <- 깜빡함\n",
    "\n",
    "print(\"수동 기록 결과:\")\n",
    "for exp in experiment_log:\n",
    "    print(f\"  {exp}\")\n",
    "\n",
    "print(\"\\n문제점:\")\n",
    "print(\"  - 실험 3 기록 누락\")\n",
    "print(\"  - 모델 파일 위치 없음\")\n",
    "print(\"  - 재현 불가능\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 MLflow가 해결하는 것\n",
    "\n",
    "MLflow는 ML 실험의 **모든 것을 자동으로 기록**합니다:\n",
    "\n",
    "| 항목 | 수동 기록 | MLflow |\n",
    "|------|----------|--------|\n",
    "| 파라미터 | 엑셀/노트 | 자동 저장 |\n",
    "| 메트릭 | 기억에 의존 | 자동 저장 + 시각화 |\n",
    "| 모델 파일 | `model_final_v3.pkl` | 버전별 관리 |\n",
    "| 재현성 | 불가능 | 코드 + 환경 저장 |\n",
    "| 비교 | 직접 비교 | UI에서 한눈에 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 MLflow 4가지 컴포넌트\n",
    "\n",
    "```\n",
    "+-------------------------------------------------------+\n",
    "|                      MLflow                            |\n",
    "+-------------+-------------+-------------+--------------+\n",
    "|  Tracking   |  Registry   |  Projects   |   Serving    |\n",
    "|  실험 기록   |  모델 저장소 |  재현 환경   |   모델 배포   |\n",
    "|  <- 오늘!   |  <- 2-S2!   |  (선택)     |   (선택)     |\n",
    "+-------------+-------------+-------------+--------------+\n",
    "```\n",
    "\n",
    "**오늘 배울 것: Tracking** (실험 파라미터, 메트릭 기록)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. MLflow Tracking 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 핵심 개념\n",
    "\n",
    "```\n",
    "Experiment (실험 그룹) - \"FDS-XGBoost-튜닝\"\n",
    "|\n",
    "+-- Run 1 (한 번의 학습)\n",
    "|   +-- Parameters: {learning_rate: 0.1, max_depth: 6}\n",
    "|   +-- Metrics: {auc: 0.85, recall: 0.80}\n",
    "|   +-- Artifacts: model.pkl, feature_importance.png\n",
    "|\n",
    "+-- Run 2\n",
    "|   +-- Parameters: {learning_rate: 0.05, max_depth: 8}\n",
    "|   +-- Metrics: {auc: 0.87, recall: 0.82}\n",
    "|   +-- Artifacts: model.pkl\n",
    "|\n",
    "+-- Run 3\n",
    "    +-- ...\n",
    "```\n",
    "\n",
    "| 용어 | 설명 | 예시 |\n",
    "|------|------|------|\n",
    "| **Experiment** | 실험 그룹 | \"FDS-XGBoost-튜닝\" |\n",
    "| **Run** | 한 번의 학습 | Optuna 50회 = 50 Runs |\n",
    "| **Parameter** | 입력 설정 | learning_rate, max_depth |\n",
    "| **Metric** | 결과 수치 | AUC, Recall, AUPRC |\n",
    "| **Artifact** | 결과 파일 | model.pkl, plots |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Tracking 기본 예제\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# 1. 실험 설정 (없으면 자동 생성)\n",
    "mlflow.set_experiment(\"FDS-Study-Tracking\")\n",
    "\n",
    "# 2. Run 시작\n",
    "with mlflow.start_run(run_name=\"tracking-basic\"):\n",
    "    \n",
    "    # 3. 파라미터 기록\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"max_depth\", 6)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    \n",
    "    # 4. 메트릭 기록\n",
    "    mlflow.log_metric(\"auc\", 0.85)\n",
    "    mlflow.log_metric(\"recall\", 0.80)\n",
    "    mlflow.log_metric(\"precision\", 0.75)\n",
    "    \n",
    "    # Run ID 확인\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "\n",
    "print(\"\\n기록 완료!\")\n",
    "print(\"MLflow UI에서 확인: mlflow ui 명령 실행 후 http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 실제 모델 학습 + 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 XGBoost 학습 + MLflow 기록\n",
    "\n",
    "mlflow.set_experiment(\"FDS-Study-Tracking\")\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 50,\n",
    "    'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost-manual-logging\"):\n",
    "    \n",
    "    # 파라미터 기록\n",
    "    for key, value in params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측 및 평가\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 메트릭 기록\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # FDS 비용 지표 (커스텀)\n",
    "    # FN 비용 100만원, FP 비용 5만원\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fn_cost = cm[1, 0] * 1000000  # 사기 놓침\n",
    "    fp_cost = cm[0, 1] * 50000    # 오탐\n",
    "    total_cost = fn_cost + fp_cost\n",
    "    mlflow.log_metric(\"total_cost\", total_cost)\n",
    "    \n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"총 비용: {total_cost:,}원\")\n",
    "    print(f\"\\nRun ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 1: 수동 로깅\n",
    "\n",
    "다른 하이퍼파라미터로 학습하고 MLflow에 기록하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 1: 수동 로깅\n",
    "\n",
    "mlflow.set_experiment(\"FDS-Study-Tracking\")\n",
    "\n",
    "# TODO: 다른 하이퍼파라미터 설정\n",
    "params_v2 = {\n",
    "    'learning_rate': 0.05,      # TODO: 변경해보세요\n",
    "    'max_depth': 8,             # TODO: 변경해보세요\n",
    "    'n_estimators': 100,        # TODO: 변경해보세요\n",
    "    'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost-practice-1\"):\n",
    "    \n",
    "    # TODO: 파라미터 기록 (힌트: mlflow.log_param())\n",
    "    for key, value in params_v2.items():\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # TODO: 모델 학습\n",
    "    model_v2 = xgb.XGBClassifier(**params_v2)\n",
    "    model_v2.fit(X_train, y_train)\n",
    "    \n",
    "    # TODO: 예측 및 평가\n",
    "    y_pred_v2 = model_v2.predict(X_test)\n",
    "    y_proba_v2 = model_v2.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # TODO: 메트릭 계산 및 기록\n",
    "    auc_v2 = roc_auc_score(y_test, y_proba_v2)\n",
    "    recall_v2 = recall_score(y_test, y_pred_v2)\n",
    "    \n",
    "    mlflow.log_metric(\"auc\", auc_v2)\n",
    "    mlflow.log_metric(\"recall\", recall_v2)\n",
    "    \n",
    "    practice1_run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"AUC: {auc_v2:.4f}\")\n",
    "    print(f\"Recall: {recall_v2:.4f}\")\n",
    "    print(f\"Run ID: {practice1_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 1\n",
    "assert practice1_run_id is not None, \"Run ID가 없습니다. MLflow Run을 실행하세요.\"\n",
    "assert auc_v2 > 0.5, \"AUC가 너무 낮습니다. 모델 학습을 확인하세요.\"\n",
    "\n",
    "print(\"체크포인트 1 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Autolog - 자동 기록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 수동 로깅 vs Autolog\n",
    "\n",
    "```python\n",
    "# 수동 로깅 - 일일이 기록\n",
    "mlflow.log_param(\"learning_rate\", 0.1)\n",
    "mlflow.log_param(\"max_depth\", 6)\n",
    "mlflow.log_param(\"n_estimators\", 100)\n",
    "# ... 10줄 더...\n",
    "\n",
    "# Autolog - 한 줄로 끝!\n",
    "mlflow.sklearn.autolog()  # XGBClassifier용\n",
    "```\n",
    "\n",
    "**중요: Autolog 종류**\n",
    "\n",
    "| 사용하는 API | Autolog 함수 |\n",
    "|-------------|--------------|\n",
    "| `XGBClassifier`, `XGBRegressor` (sklearn API) | `mlflow.sklearn.autolog()` |\n",
    "| `xgb.train()` (native API) | `mlflow.xgboost.autolog()` |\n",
    "\n",
    "```python\n",
    "# 잘못된 사용 (에러 발생!)\n",
    "mlflow.xgboost.autolog()\n",
    "model = XGBClassifier()  # sklearn API인데 xgboost autolog 사용\n",
    "\n",
    "# 올바른 사용\n",
    "mlflow.sklearn.autolog()\n",
    "model = XGBClassifier()  # sklearn API -> sklearn autolog\n",
    "```\n",
    "\n",
    "**Autolog가 자동으로 기록하는 것:**\n",
    "- 모든 하이퍼파라미터\n",
    "- 학습 메트릭 (loss 등)\n",
    "- 모델 파일\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autolog 예제\n",
    "\n",
    "mlflow.set_experiment(\"FDS-Study-Autolog\")\n",
    "\n",
    "# sklearn autolog 활성화 (XGBClassifier는 sklearn API 사용)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost-autolog\"):\n",
    "    \n",
    "    # 모델 학습만 하면 됨!\n",
    "    model_auto = xgb.XGBClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model_auto.fit(X_train, y_train)\n",
    "    \n",
    "    # 자동으로 기록됨:\n",
    "    # - 모든 하이퍼파라미터\n",
    "    # - 모델 파일\n",
    "    # - Feature importance\n",
    "    \n",
    "    autolog_run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"\\nAutolog 완료!\")\n",
    "    print(f\"Run ID: {autolog_run_id}\")\n",
    "    print(\"\\n자동으로 기록된 것:\")\n",
    "    print(\"  - 모든 하이퍼파라미터\")\n",
    "    print(\"  - 모델 파일 (model/)\")\n",
    "    print(\"  - Feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Autolog의 한계\n",
    "\n",
    "**Autolog가 기록하지 않는 것:**\n",
    "- 커스텀 메트릭 (FDS 비용, AUPRC 등)\n",
    "- 테스트 데이터 평가 결과\n",
    "- 비즈니스 지표\n",
    "\n",
    "**-> 실무에서는 Autolog + 수동 로깅 조합 사용!**\n",
    "\n",
    "**Autolog 주의사항:**\n",
    "- `XGBClassifier` 사용 시 -> `mlflow.sklearn.autolog()`\n",
    "- `xgb.train()` 사용 시 -> `mlflow.xgboost.autolog()`\n",
    "- 잘못 사용하면 `_estimator_type undefined` 에러 발생!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autolog + 수동 로깅 조합 (실무 패턴)\n",
    "\n",
    "mlflow.set_experiment(\"FDS-Study-Autolog\")\n",
    "\n",
    "# sklearn autolog (XGBClassifier용)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost-autolog-custom\"):\n",
    "    \n",
    "    # 모델 학습 (Autolog가 자동 기록)\n",
    "    model_combo = xgb.XGBClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model_combo.fit(X_train, y_train)\n",
    "    \n",
    "    # 수동으로 커스텀 메트릭 추가\n",
    "    y_pred_combo = model_combo.predict(X_test)\n",
    "    y_proba_combo = model_combo.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 테스트 메트릭\n",
    "    test_auc = roc_auc_score(y_test, y_proba_combo)\n",
    "    test_recall = recall_score(y_test, y_pred_combo)\n",
    "    mlflow.log_metric(\"test_auc\", test_auc)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    \n",
    "    # FDS 비용 지표 (커스텀)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_combo)\n",
    "    total_cost = cm[1, 0] * 1000000 + cm[0, 1] * 50000\n",
    "    mlflow.log_metric(\"total_cost\", total_cost)\n",
    "    \n",
    "    combo_run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Test AUC: {test_auc:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"총 비용: {total_cost:,}원\")\n",
    "    print(f\"\\nRun ID: {combo_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 2: Autolog 사용\n",
    "\n",
    "Autolog를 사용하여 학습하고, 커스텀 메트릭을 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 2: Autolog + 커스텀 메트릭\n",
    "\n",
    "mlflow.set_experiment(\"FDS-Study-Autolog\")\n",
    "\n",
    "# sklearn autolog (XGBClassifier용)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"practice-autolog\"):\n",
    "    \n",
    "    # TODO: 다른 하이퍼파라미터로 모델 학습\n",
    "    model_practice = xgb.XGBClassifier(\n",
    "        n_estimators=100,       # TODO: 변경해보세요\n",
    "        learning_rate=0.05,     # TODO: 변경해보세요\n",
    "        max_depth=8,            # TODO: 변경해보세요\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model_practice.fit(X_train, y_train)\n",
    "    \n",
    "    # TODO: 테스트 데이터 예측\n",
    "    y_pred_practice = model_practice.predict(X_test)\n",
    "    y_proba_practice = model_practice.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # TODO: 테스트 메트릭 계산 및 기록\n",
    "    practice_auc = roc_auc_score(y_test, y_proba_practice)\n",
    "    practice_recall = recall_score(y_test, y_pred_practice)\n",
    "    \n",
    "    mlflow.log_metric(\"test_auc\", practice_auc)\n",
    "    mlflow.log_metric(\"test_recall\", practice_recall)\n",
    "    \n",
    "    practice2_run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Test AUC: {practice_auc:.4f}\")\n",
    "    print(f\"Test Recall: {practice_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 2\n",
    "assert practice2_run_id is not None, \"Run ID가 없습니다.\"\n",
    "assert practice_auc > 0.5, \"AUC가 너무 낮습니다.\"\n",
    "assert practice_recall > 0, \"Recall을 계산하세요.\"\n",
    "\n",
    "print(\"체크포인트 2 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 최종 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"  2-S1 완료: MLflow Tracking 기초\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"배운 것:\")\n",
    "print()\n",
    "print(\"1. 왜 MLflow가 필요한가?\")\n",
    "print(\"   - 실험 재현성\")\n",
    "print(\"   - 하이퍼파라미터/메트릭 자동 기록\")\n",
    "print()\n",
    "print(\"2. MLflow Tracking\")\n",
    "print(\"   - Experiment -> Run -> Artifact 구조\")\n",
    "print(\"   - log_param(), log_metric()\")\n",
    "print()\n",
    "print(\"3. Autolog\")\n",
    "print(\"   - mlflow.sklearn.autolog() (XGBClassifier용)\")\n",
    "print(\"   - 자동 기록 + 커스텀 메트릭 조합\")\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"다음: 2-S2 Model Registry로!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 체크리스트\n",
    "\n",
    "| 항목 | 이해도 |\n",
    "|------|--------|\n",
    "| Experiment, Run, Artifact 구조 | |\n",
    "| log_param(), log_metric() 사용법 | |\n",
    "| Autolog 사용법 및 한계 | |\n",
    "| Autolog + 수동 로깅 조합 (실무) | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 면접 예상 질문\n",
    "\n",
    "**1. \"MLflow Tracking은 무엇을 기록하나요?\"**\n",
    "\n",
    "답변:\n",
    "- **파라미터**: 모델 학습에 사용한 하이퍼파라미터 (learning_rate, max_depth 등)\n",
    "- **메트릭**: 모델 성능 지표 (AUC, Recall, 비용 등)\n",
    "- **아티팩트**: 모델 파일, 그래프, 데이터 샘플 등\n",
    "\n",
    "---\n",
    "\n",
    "**2. \"Autolog의 장단점은?\"**\n",
    "\n",
    "답변:\n",
    "- **장점**: 편리함, 일관성, 모든 하이퍼파라미터 자동 기록\n",
    "- **단점**: 커스텀 메트릭(FDS 비용, AUPRC) 수동 추가 필요\n",
    "- **실무**: Autolog + 수동 로깅 조합 사용\n",
    "- **주의**: XGBClassifier는 `mlflow.sklearn.autolog()`, xgb.train()은 `mlflow.xgboost.autolog()` 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
