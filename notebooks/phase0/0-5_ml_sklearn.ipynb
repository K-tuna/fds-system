{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-5: ML ê°œë… + Sklearn\n",
    "\n",
    "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ ê°œë…ê³¼ Sklearn ì‚¬ìš©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. ML ê¸°ì´ˆ (ë¶„ë¥˜ vs íšŒê·€)\n",
    "2. ê³¼ì í•©ê³¼ train/test split\n",
    "3. fit â†’ predict íŒ¨í„´\n",
    "4. í‰ê°€ ì§€í‘œ (Accuracy, Recall, Precision, AUC)\n",
    "5. íŠ¸ë¦¬ ëª¨ë¸ ë¹„êµ (Decision Tree, Random Forest, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. MLì´ë€?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ë¶„ë¥˜ vs íšŒê·€\n",
    "\n",
    "| ìœ í˜• | ì¶œë ¥ | ì˜ˆì‹œ |\n",
    "|-----|-----|-----|\n",
    "| **ë¶„ë¥˜ (Classification)** | ë²”ì£¼ (0/1, A/B/C) | ì‚¬ê¸° íƒì§€, ìŠ¤íŒ¸ ë¶„ë¥˜ |\n",
    "| **íšŒê·€ (Regression)** | ì—°ì†ê°’ | ì§‘ê°’ ì˜ˆì¸¡, ë§¤ì¶œ ì˜ˆì¸¡ |\n",
    "\n",
    "**FDSëŠ” ë¶„ë¥˜ ë¬¸ì œ**: ì‚¬ê¸°(1) vs ì •ìƒ(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ê³¼ì í•©ê³¼ ë°ì´í„° ë¶„í• "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ì™œ train/testë¥¼ ë‚˜ëˆ„ëŠ”ê°€?\n",
    "\n",
    "- **ê³¼ì í•©(Overfitting)**: í•™ìŠµ ë°ì´í„°ë§Œ ì˜ ë§ì¶”ê³ , ìƒˆ ë°ì´í„°ì— ì‹¤íŒ¨\n",
    "- í•´ê²°: í•™ìŠµì— ì•ˆ ì“´ ë°ì´í„°(test)ë¡œ ì„±ëŠ¥ ê²€ì¦\n",
    "\n",
    "```\n",
    "ì „ì²´ ë°ì´í„°\n",
    "â”œâ”€â”€ Train (80%) â†’ ëª¨ë¸ í•™ìŠµ\n",
    "â””â”€â”€ Test (20%)  â†’ ì„±ëŠ¥ í‰ê°€\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# íŠ¹ì„± (Feature)\n",
    "amount = np.random.exponential(50000, n_samples)\n",
    "hour = np.random.randint(0, 24, n_samples)\n",
    "is_foreign = np.random.randint(0, 2, n_samples)\n",
    "\n",
    "# íƒ€ê²Ÿ (Label) - ê³ ì•¡ + ìƒˆë²½ + í•´ì™¸ = ì‚¬ê¸° í™•ë¥  ë†’ìŒ\n",
    "fraud_prob = 0.01 + 0.05 * (amount > 100000) + 0.1 * ((hour < 6) | (hour > 22)) + 0.1 * is_foreign\n",
    "is_fraud = (np.random.random(n_samples) < fraud_prob).astype(int)\n",
    "\n",
    "# DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'amount': amount,\n",
    "    'hour': hour,\n",
    "    'is_foreign': is_foreign,\n",
    "    'is_fraud': is_fraud\n",
    "})\n",
    "\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "print(f\"ì‚¬ê¸° ë¹„ìœ¨: {df['is_fraud'].mean():.2%}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š train_test_split\n",
    "X = df[['amount', 'hour', 'is_foreign']]  # íŠ¹ì„±\n",
    "y = df['is_fraud']                         # íƒ€ê²Ÿ\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% í…ŒìŠ¤íŠ¸ìš©\n",
    "    random_state=42     # ì¬í˜„ì„±\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’» ì‹¤ìŠµ 1: train_test_split\n",
    "\n",
    "ë°ì´í„°ë¥¼ 70:30 ë¹„ìœ¨ë¡œ ë¶„í• í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’» ì‹¤ìŠµ 1\n",
    "# TODO: 70:30 ë¹„ìœ¨ë¡œ ë¶„í•  (test_size=0.3, random_state=42)\n",
    "X_train_70, X_test_30, y_train_70, y_test_30 = None, None, None, None  # TODO\n",
    "\n",
    "print(f\"Train: {len(X_train_70)}, Test: {len(X_test_30)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ 1\n",
    "assert len(X_train_70) == 700, \"Train 700ê°œ\"\n",
    "assert len(X_test_30) == 300, \"Test 300ê°œ\"\n",
    "\n",
    "print(\"âœ… ì²´í¬í¬ì¸íŠ¸ 1 í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. fit â†’ predict íŒ¨í„´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š sklearn ê³µí†µ íŒ¨í„´\n",
    "# 1. ëª¨ë¸ ìƒì„±\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2. í•™ìŠµ (fit)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡ (predict)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 10ê°œ):\")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š predict_proba: í™•ë¥  ì˜ˆì¸¡\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(\"í™•ë¥  ì˜ˆì¸¡ (ì²˜ìŒ 5ê°œ):\")\n",
    "print(\"[ì •ìƒ í™•ë¥ , ì‚¬ê¸° í™•ë¥ ]\")\n",
    "print(y_proba[:5])\n",
    "\n",
    "# ì‚¬ê¸° í™•ë¥ ë§Œ\n",
    "fraud_prob = y_proba[:, 1]\n",
    "print(f\"\\nì‚¬ê¸° í™•ë¥ : {fraud_prob[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’» ì‹¤ìŠµ 2: fit/predict\n",
    "\n",
    "RandomForestë¡œ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’» ì‹¤ìŠµ 2\n",
    "# TODO: RandomForestClassifier ìƒì„± (n_estimators=100, random_state=42)\n",
    "rf_model = None  # TODO\n",
    "\n",
    "# TODO: í•™ìŠµ\n",
    "\n",
    "# TODO: ì˜ˆì¸¡\n",
    "rf_pred = None  # TODO\n",
    "\n",
    "# TODO: ì‚¬ê¸° í™•ë¥  ì˜ˆì¸¡\n",
    "rf_proba = None  # TODO ([:, 1]ë¡œ ì‚¬ê¸° í™•ë¥ ë§Œ)\n",
    "\n",
    "print(f\"ì˜ˆì¸¡: {rf_pred[:10]}\")\n",
    "print(f\"í™•ë¥ : {rf_proba[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ 2\n",
    "assert rf_model is not None, \"ëª¨ë¸ ìƒì„± í•„ìš”\"\n",
    "assert len(rf_pred) == len(X_test), \"ì˜ˆì¸¡ ê°œìˆ˜ ì¼ì¹˜\"\n",
    "assert 0 <= rf_proba.min() <= rf_proba.max() <= 1, \"í™•ë¥ ì€ 0~1\"\n",
    "\n",
    "print(\"âœ… ì²´í¬í¬ì¸íŠ¸ 2 í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í‰ê°€ ì§€í‘œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š ë¶„ë¥˜ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "| ì§€í‘œ | ì˜ë¯¸ | FDS ê´€ì  |\n",
    "|-----|-----|--------|\n",
    "| **Accuracy** | ì „ì²´ ì •í™•ë„ | ë¶ˆê· í˜• ë°ì´í„°ì—ì„  ë¬´ì˜ë¯¸ |\n",
    "| **Recall** | ì‹¤ì œ ì‚¬ê¸° ì¤‘ íƒì§€ ë¹„ìœ¨ | **ê°€ì¥ ì¤‘ìš”** (ë†“ì¹˜ë©´ ì•ˆë¨) |\n",
    "| **Precision** | ì˜ˆì¸¡ ì‚¬ê¸° ì¤‘ ì‹¤ì œ ì‚¬ê¸° | ë†’ìœ¼ë©´ ì˜¤íƒ ì ìŒ |\n",
    "| **AUC** | ì „ì²´ ì„±ëŠ¥ | 0.5=ëœë¤, 1.0=ì™„ë²½ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"í˜¼ë™ í–‰ë ¬:\")\n",
    "print(cm)\n",
    "print()\n",
    "print(\"         ì˜ˆì¸¡=ì •ìƒ  ì˜ˆì¸¡=ì‚¬ê¸°\")\n",
    "print(f\"ì‹¤ì œ=ì •ìƒ   {cm[0,0]:5d}    {cm[0,1]:5d}  (TN, FP)\")\n",
    "print(f\"ì‹¤ì œ=ì‚¬ê¸°   {cm[1,0]:5d}    {cm[1,1]:5d}  (FN, TP)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}  â† ì‚¬ê¸° íƒì§€ìœ¨\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"AUC:       {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’» ì‹¤ìŠµ 3: í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "\n",
    "RandomForest ëª¨ë¸ì˜ í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’» ì‹¤ìŠµ 3\n",
    "# TODO: RandomForest ì˜ˆì¸¡ ê²°ê³¼(rf_pred, rf_proba)ë¡œ í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "rf_acc = None   # TODO: accuracy_score\n",
    "rf_rec = None   # TODO: recall_score\n",
    "rf_prec = None  # TODO: precision_score\n",
    "rf_auc = None   # TODO: roc_auc_score\n",
    "\n",
    "print(f\"RandomForest ì„±ëŠ¥:\")\n",
    "print(f\"  Accuracy:  {rf_acc:.4f}\")\n",
    "print(f\"  Recall:    {rf_rec:.4f}\")\n",
    "print(f\"  Precision: {rf_prec:.4f}\")\n",
    "print(f\"  AUC:       {rf_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ 3\n",
    "assert rf_acc is not None, \"Accuracy ê³„ì‚° í•„ìš”\"\n",
    "assert 0 <= rf_rec <= 1, \"Recallì€ 0~1\"\n",
    "assert 0 <= rf_auc <= 1, \"AUCëŠ” 0~1\"\n",
    "\n",
    "print(\"âœ… ì²´í¬í¬ì¸íŠ¸ 3 í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. íŠ¸ë¦¬ ëª¨ë¸ ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š íŠ¸ë¦¬ ëª¨ë¸ ì§„í™”\n",
    "\n",
    "```\n",
    "Decision Tree â†’ Random Forest â†’ XGBoost\n",
    "   (ë‹¨ì¼ íŠ¸ë¦¬)    (ì—¬ëŸ¬ íŠ¸ë¦¬ íˆ¬í‘œ)   (ìˆœì°¨ í•™ìŠµ)\n",
    "```\n",
    "\n",
    "- **Decision Tree**: ë‹¨ìˆœ, ê³¼ì í•© ì‰¬ì›€\n",
    "- **Random Forest**: ì—¬ëŸ¬ íŠ¸ë¦¬ ì•™ìƒë¸”, ì•ˆì •ì \n",
    "- **XGBoost**: Gradient Boosting, ì„±ëŠ¥ ìµœê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’» ì‹¤ìŠµ 4: 3ê°œ ëª¨ë¸ ë¹„êµ\n",
    "\n",
    "Decision Tree, Random Forest, XGBoost ì„±ëŠ¥ì„ ë¹„êµí•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’» ì‹¤ìŠµ 4\n",
    "results = []\n",
    "\n",
    "# TODO: 3ê°œ ëª¨ë¸ ì •ì˜\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': None,  # TODO: n_estimators=100\n",
    "    'XGBoost': None        # TODO: n_estimators=100, eval_metric='logloss'\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if model is None:\n",
    "        continue\n",
    "    \n",
    "    # TODO: í•™ìŠµ\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # TODO: ì˜ˆì¸¡\n",
    "    pred = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # í‰ê°€\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, pred),\n",
    "        'Recall': recall_score(y_test, pred),\n",
    "        'Precision': precision_score(y_test, pred, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_test, proba)\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ 4\n",
    "assert len(result_df) == 3, \"3ê°œ ëª¨ë¸ ê²°ê³¼ í•„ìš”\"\n",
    "assert 'XGBoost' in result_df['Model'].values, \"XGBoost í¬í•¨\"\n",
    "\n",
    "print(\"âœ… ì²´í¬í¬ì¸íŠ¸ 4 í†µê³¼!\")\n",
    "print()\n",
    "print(\"ì¼ë°˜ì ìœ¼ë¡œ XGBoost â‰¥ RandomForest > DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… ìµœì¢… ì²´í¬í¬ì¸íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"ğŸ‰ 0-5 ì™„ë£Œ: ML ê°œë… + Sklearn\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"ë°°ìš´ ê²ƒ:\")\n",
    "print(\"  - ë¶„ë¥˜ vs íšŒê·€ (FDS = ë¶„ë¥˜)\")\n",
    "print(\"  - train_test_split (ê³¼ì í•© ë°©ì§€)\")\n",
    "print(\"  - fit â†’ predict íŒ¨í„´\")\n",
    "print(\"  - í‰ê°€ ì§€í‘œ: Accuracy, Recall, Precision, AUC\")\n",
    "print(\"  - FDSì—ì„œ Recallì´ ì¤‘ìš” (ì‚¬ê¸° ë†“ì¹˜ë©´ ì•ˆë¨)\")\n",
    "print(\"  - íŠ¸ë¦¬ ëª¨ë¸: DecisionTree â†’ RandomForest â†’ XGBoost\")\n",
    "print()\n",
    "print(\"ë‹¤ìŒ: 0-6 ëª¨ë¸ ì €ì¥/íŠœë‹/ì„¤ëª…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fds)",
   "language": "python",
   "name": "fds"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
