{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-S7: FastAPI ê¸°ì´ˆ\n",
    "\n",
    "ML ëª¨ë¸ì„ REST APIë¡œ ì„œë¹™í•˜ê¸° ìœ„í•œ FastAPIë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. **FastAPI ê¸°ë³¸** - ë¼ìš°íŒ…, ìš”ì²­/ì‘ë‹µ\n",
    "2. **Pydantic** - ë°ì´í„° ê²€ì¦ ìŠ¤í‚¤ë§ˆ\n",
    "3. **ë¹„ë™ê¸° ì²˜ë¦¬** - async/await\n",
    "4. **ëª¨ë¸ ì„œë¹™ íŒ¨í„´** - ë¡œë”©, ì˜ˆì¸¡, ì‘ë‹µ\n",
    "5. **Docker ê¸°ì´ˆ** - ì»¨í…Œì´ë„ˆí™”\n",
    "\n",
    "## ì˜ˆìƒ ì‹œê°„\n",
    "ì•½ 30ë¶„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.128.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi)\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\82109\\miniconda3\\envs\\fds\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\82109\\miniconda3\\envs\\fds\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\82109\\miniconda3\\envs\\fds\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n",
      "Collecting click>=7.0 (from uvicorn)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\82109\\miniconda3\\envs\\fds\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\82109\\miniconda3\\envs\\fds\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Downloading fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
      "Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 11.2 MB/s  0:00:00\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, click, annotated-types, annotated-doc, uvicorn, starlette, pydantic, fastapi\n",
      "\n",
      "   -------- ------------------------------- 2/9 [click]\n",
      "   ---------------------- ----------------- 5/9 [uvicorn]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ---------------------------------------- 9/9 [fastapi]\n",
      "\n",
      "Successfully installed annotated-doc-0.0.4 annotated-types-0.7.0 click-8.3.1 fastapi-0.128.0 pydantic-2.12.5 pydantic-core-2.41.5 starlette-0.50.0 typing-inspection-0.4.2 uvicorn-0.40.0\n",
      "íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸\n",
    "!pip install fastapi uvicorn pydantic\n",
    "\n",
    "import json\n",
    "from typing import Optional, List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "print(\"íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. FastAPIë€?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. FastAPI ê°œë…\n",
    "\n",
    "**FastAPI**: Python ê¸°ë°˜ ê³ ì„±ëŠ¥ ì›¹ í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "#### ì™œ FastAPIì¸ê°€?\n",
    "\n",
    "| í”„ë ˆì„ì›Œí¬ | íŠ¹ì§• | ML ì„œë¹™ ì í•©ì„± |\n",
    "|-----------|------|---------------|\n",
    "| **Flask** | ê°„ë‹¨, ìœ ì—° | âš ï¸ ë™ê¸° ë°©ì‹ |\n",
    "| **Django** | í’€ìŠ¤íƒ | âŒ ê³¼í•¨ |\n",
    "| **FastAPI** | ê³ ì„±ëŠ¥, ìë™ ë¬¸ì„œí™” | âœ… ìµœì  |\n",
    "\n",
    "#### FastAPI ì¥ì \n",
    "\n",
    "```\n",
    "1. ì„±ëŠ¥: Flask ëŒ€ë¹„ 3~5ë°° ë¹ ë¦„ (ë¹„ë™ê¸°)\n",
    "2. íƒ€ì… íŒíŠ¸: Pydanticìœ¼ë¡œ ìë™ ê²€ì¦\n",
    "3. ìë™ ë¬¸ì„œí™”: Swagger UI ìë™ ìƒì„±\n",
    "4. ë¹„ë™ê¸°: async/await ë„¤ì´í‹°ë¸Œ ì§€ì›\n",
    "```\n",
    "\n",
    "#### ê¸°ë³¸ êµ¬ì¡°\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")           # GET ìš”ì²­\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello FDS!\"}\n",
    "\n",
    "@app.post(\"/predict\")   # POST ìš”ì²­\n",
    "def predict(data: dict):\n",
    "    return {\"result\": \"fraud\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. HTTP ë©”ì„œë“œ\n",
    "\n",
    "| ë©”ì„œë“œ | ìš©ë„ | ì˜ˆì‹œ |\n",
    "|--------|------|------|\n",
    "| **GET** | ë°ì´í„° ì¡°íšŒ | ê±°ë˜ ëª©ë¡ ì¡°íšŒ |\n",
    "| **POST** | ë°ì´í„° ìƒì„±/ì˜ˆì¸¡ | ì‚¬ê¸° íƒì§€ ì˜ˆì¸¡ |\n",
    "| **PUT** | ë°ì´í„° ìˆ˜ì • | ëª¨ë¸ ì„¤ì • ë³€ê²½ |\n",
    "| **DELETE** | ë°ì´í„° ì‚­ì œ | ìºì‹œ ì‚­ì œ |\n",
    "\n",
    "**FDSì—ì„œ ì£¼ë¡œ ì‚¬ìš©:**\n",
    "- `POST /predict` - ì‚¬ê¸° ì˜ˆì¸¡ ìš”ì²­\n",
    "- `GET /health` - ì„œë²„ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI ê¸°ë³¸ ì½”ë“œ:\n",
      "\n",
      "from fastapi import FastAPI\n",
      "\n",
      "app = FastAPI(\n",
      "    title=\"FDS API\",\n",
      "    description=\"ì´ìƒê±°ë˜ íƒì§€ API\",\n",
      "    version=\"1.0.0\"\n",
      ")\n",
      "\n",
      "@app.get(\"/\")\n",
      "def root():\n",
      "    \"\"\"ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸\"\"\"\n",
      "    return {\"message\": \"FDS API is running!\"}\n",
      "\n",
      "@app.get(\"/health\")\n",
      "def health():\n",
      "    \"\"\"í—¬ìŠ¤ ì²´í¬\"\"\"\n",
      "    return {\"status\": \"healthy\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š FastAPI ê¸°ë³¸ êµ¬ì¡° (ì½”ë“œ ì˜ˆì‹œ)\n",
    "# ì‹¤ì œ ì‹¤í–‰ì€ .py íŒŒì¼ì—ì„œ!\n",
    "\n",
    "fastapi_example = '''\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"FDS API\",\n",
    "    description=\"ì´ìƒê±°ë˜ íƒì§€ API\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    \"\"\"ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸\"\"\"\n",
    "    return {\"message\": \"FDS API is running!\"}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    \"\"\"í—¬ìŠ¤ ì²´í¬\"\"\"\n",
    "    return {\"status\": \"healthy\"}\n",
    "'''\n",
    "\n",
    "print(\"FastAPI ê¸°ë³¸ ì½”ë“œ:\")\n",
    "print(fastapi_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Pydantic ìŠ¤í‚¤ë§ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Pydanticì´ë€?\n",
    "\n",
    "**Pydantic**: ë°ì´í„° ê²€ì¦ ë° ì„¤ì • ê´€ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "#### ì™œ Pydantic?\n",
    "\n",
    "```python\n",
    "# âŒ ìˆ˜ë™ ê²€ì¦ (ì§€ì €ë¶„)\n",
    "def predict(data: dict):\n",
    "    if \"amount\" not in data:\n",
    "        raise ValueError(\"amount í•„ìˆ˜!\")\n",
    "    if not isinstance(data[\"amount\"], (int, float)):\n",
    "        raise ValueError(\"amountëŠ” ìˆ«ì!\")\n",
    "    if data[\"amount\"] < 0:\n",
    "        raise ValueError(\"amountëŠ” ì–‘ìˆ˜!\")\n",
    "    ...\n",
    "\n",
    "# âœ… Pydantic (ê¹”ë”)\n",
    "class Transaction(BaseModel):\n",
    "    amount: float = Field(gt=0)  # ì–‘ìˆ˜ë§Œ\n",
    "    # ë! ìë™ ê²€ì¦ë¨\n",
    "```\n",
    "\n",
    "#### Pydantic ì¥ì \n",
    "\n",
    "| ê¸°ëŠ¥ | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **ìë™ íƒ€ì… ë³€í™˜** | \"123\" â†’ 123 ìë™ ë³€í™˜ |\n",
    "| **ìœ íš¨ì„± ê²€ì¦** | í•„ìˆ˜ í•„ë“œ, ë²”ìœ„ ì²´í¬ |\n",
    "| **ìë™ ë¬¸ì„œí™”** | Swagger UIì— ìŠ¤í‚¤ë§ˆ í‘œì‹œ |\n",
    "| **JSON ì§ë ¬í™”** | dict â†” JSON ìë™ ë³€í™˜ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê±°ë˜ ê°ì²´:\n",
      "  ID: TXN001\n",
      "  ê¸ˆì•¡: 50,000.0ì›\n",
      "  ì¹´ë“œ: credit\n",
      "  ì‹œê°„: 14ì‹œ\n",
      "\n",
      "JSON ë³€í™˜:\n",
      "{\n",
      "  \"transaction_id\": \"TXN001\",\n",
      "  \"amount\": 50000.0,\n",
      "  \"card_type\": \"credit\",\n",
      "  \"hour\": 14,\n",
      "  \"is_weekend\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š Pydantic ê¸°ë³¸ ì‚¬ìš©ë²•\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "# ê±°ë˜ ë°ì´í„° ìŠ¤í‚¤ë§ˆ\n",
    "class Transaction(BaseModel):\n",
    "    \"\"\"ê±°ë˜ ì •ë³´ ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    transaction_id: str\n",
    "    amount: float = Field(gt=0, description=\"ê±°ë˜ ê¸ˆì•¡ (ì–‘ìˆ˜)\")\n",
    "    card_type: str = Field(default=\"credit\", description=\"ì¹´ë“œ ì¢…ë¥˜\")\n",
    "    hour: int = Field(ge=0, le=23, description=\"ê±°ë˜ ì‹œê°„ (0-23)\")\n",
    "    is_weekend: bool = False\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "txn = Transaction(\n",
    "    transaction_id=\"TXN001\",\n",
    "    amount=50000,\n",
    "    hour=14\n",
    ")\n",
    "\n",
    "print(\"ê±°ë˜ ê°ì²´:\")\n",
    "print(f\"  ID: {txn.transaction_id}\")\n",
    "print(f\"  ê¸ˆì•¡: {txn.amount:,}ì›\")\n",
    "print(f\"  ì¹´ë“œ: {txn.card_type}\")\n",
    "print(f\"  ì‹œê°„: {txn.hour}ì‹œ\")\n",
    "print(f\"\\nJSON ë³€í™˜:\")\n",
    "print(txn.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ íš¨ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸:\n",
      "----------------------------------------\n",
      "âœ… ì •ìƒ ë°ì´í„°: í†µê³¼\n",
      "âœ… ìŒìˆ˜ ê¸ˆì•¡ ê±°ë¶€ë¨\n",
      "âœ… ì˜ëª»ëœ ì‹œê°„ ê±°ë¶€ë¨\n",
      "âœ… í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ê±°ë¶€ë¨\n",
      "----------------------------------------\n",
      "â†’ Pydanticì´ ìë™ìœ¼ë¡œ ê²€ì¦!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š ìœ íš¨ì„± ê²€ì¦ ì˜ˆì‹œ\n",
    "\n",
    "print(\"ìœ íš¨ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1. ì •ìƒ ì¼€ì´ìŠ¤\n",
    "try:\n",
    "    txn = Transaction(\n",
    "        transaction_id=\"TXN001\",\n",
    "        amount=50000,\n",
    "        hour=14\n",
    "    )\n",
    "    print(\"âœ… ì •ìƒ ë°ì´í„°: í†µê³¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# 2. ìŒìˆ˜ ê¸ˆì•¡\n",
    "try:\n",
    "    txn = Transaction(\n",
    "        transaction_id=\"TXN002\",\n",
    "        amount=-1000,  # ìŒìˆ˜!\n",
    "        hour=14\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âœ… ìŒìˆ˜ ê¸ˆì•¡ ê±°ë¶€ë¨\")\n",
    "\n",
    "# 3. ì˜ëª»ëœ ì‹œê°„\n",
    "try:\n",
    "    txn = Transaction(\n",
    "        transaction_id=\"TXN003\",\n",
    "        amount=50000,\n",
    "        hour=25  # 0-23 ë²”ìœ„ ë²—ì–´ë‚¨!\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âœ… ì˜ëª»ëœ ì‹œê°„ ê±°ë¶€ë¨\")\n",
    "\n",
    "# 4. í•„ìˆ˜ í•„ë“œ ëˆ„ë½\n",
    "try:\n",
    "    txn = Transaction(\n",
    "        amount=50000,\n",
    "        hour=14\n",
    "        # transaction_id ëˆ„ë½!\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"âœ… í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ê±°ë¶€ë¨\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"â†’ Pydanticì´ ìë™ìœ¼ë¡œ ê²€ì¦!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ:\n",
      "{\n",
      "  \"transaction_id\": \"TXN001\",\n",
      "  \"fraud_probability\": 0.87,\n",
      "  \"is_fraud\": true,\n",
      "  \"top_factors\": [\n",
      "    {\n",
      "      \"feature\": \"amount\",\n",
      "      \"feature_kr\": \"ê±°ë˜ê¸ˆì•¡\",\n",
      "      \"impact\": 0.25,\n",
      "      \"direction\": \"increase\"\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"hour\",\n",
      "      \"feature_kr\": \"ê±°ë˜ì‹œê°„\",\n",
      "      \"impact\": 0.18,\n",
      "      \"direction\": \"increase\"\n",
      "    }\n",
      "  ],\n",
      "  \"explanation_text\": \"[ì‚¬ê¸° íŒë‹¨ ê·¼ê±°]\\n- ê±°ë˜ê¸ˆì•¡: ì‚¬ê¸° ìœ„í—˜ ì¦ê°€ (ì˜í–¥ë„ ì¤‘ê°„)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š FDS API ìŠ¤í‚¤ë§ˆ ì„¤ê³„\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "# ìš”ì²­ ìŠ¤í‚¤ë§ˆ\n",
    "class PredictRequest(BaseModel):\n",
    "    \"\"\"ì˜ˆì¸¡ ìš”ì²­\"\"\"\n",
    "    transaction_id: str\n",
    "    amount: float = Field(gt=0)\n",
    "    hour: int = Field(ge=0, le=23)\n",
    "    card_type: str\n",
    "    email_domain: Optional[str] = None\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ - í”¼ì²˜ ê¸°ì—¬ë„\n",
    "class FeatureFactor(BaseModel):\n",
    "    \"\"\"SHAP í”¼ì²˜ ê¸°ì—¬ë„\"\"\"\n",
    "    feature: str\n",
    "    feature_kr: str\n",
    "    impact: float\n",
    "    direction: str  # \"increase\" or \"decrease\"\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ - ì˜ˆì¸¡ ê²°ê³¼\n",
    "class PredictResponse(BaseModel):\n",
    "    \"\"\"ì˜ˆì¸¡ ì‘ë‹µ\"\"\"\n",
    "    transaction_id: str\n",
    "    fraud_probability: float = Field(ge=0, le=1)\n",
    "    is_fraud: bool\n",
    "    top_factors: List[FeatureFactor]\n",
    "    explanation_text: str\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "response = PredictResponse(\n",
    "    transaction_id=\"TXN001\",\n",
    "    fraud_probability=0.87,\n",
    "    is_fraud=True,\n",
    "    top_factors=[\n",
    "        FeatureFactor(feature=\"amount\", feature_kr=\"ê±°ë˜ê¸ˆì•¡\", impact=0.25, direction=\"increase\"),\n",
    "        FeatureFactor(feature=\"hour\", feature_kr=\"ê±°ë˜ì‹œê°„\", impact=0.18, direction=\"increase\"),\n",
    "    ],\n",
    "    explanation_text=\"[ì‚¬ê¸° íŒë‹¨ ê·¼ê±°]\\n- ê±°ë˜ê¸ˆì•¡: ì‚¬ê¸° ìœ„í—˜ ì¦ê°€ (ì˜í–¥ë„ ì¤‘ê°„)\"\n",
    ")\n",
    "\n",
    "print(\"ì˜ˆì¸¡ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ:\")\n",
    "print(response.model_dump_json(indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë¹„ë™ê¸° ì²˜ë¦¬ (async/await)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. ë™ê¸° vs ë¹„ë™ê¸°\n",
    "\n",
    "| êµ¬ë¶„ | ë™ê¸° (Sync) | ë¹„ë™ê¸° (Async) |\n",
    "|------|------------|---------------|\n",
    "| ì²˜ë¦¬ ë°©ì‹ | ìˆœì°¨ ì‹¤í–‰ | ë³‘ë ¬ ì‹¤í–‰ |\n",
    "| I/O ëŒ€ê¸° | ë¸”ë¡œí‚¹ | ë…¼ë¸”ë¡œí‚¹ |\n",
    "| ë™ì‹œ ìš”ì²­ | 1ê°œì”© | ì—¬ëŸ¬ ê°œ ë™ì‹œ |\n",
    "\n",
    "#### ë™ê¸° ë°©ì‹ (Flask ìŠ¤íƒ€ì¼)\n",
    "\n",
    "```\n",
    "ìš”ì²­1 â†’ [ì²˜ë¦¬...] â†’ ì‘ë‹µ1\n",
    "                         ìš”ì²­2 â†’ [ì²˜ë¦¬...] â†’ ì‘ë‹µ2\n",
    "                                                  ìš”ì²­3 â†’ ...\n",
    "```\n",
    "\n",
    "#### ë¹„ë™ê¸° ë°©ì‹ (FastAPI ìŠ¤íƒ€ì¼)\n",
    "\n",
    "```\n",
    "ìš”ì²­1 â†’ [ì²˜ë¦¬...]     â†’ ì‘ë‹µ1\n",
    "ìš”ì²­2 â†’     [ì²˜ë¦¬...] â†’ ì‘ë‹µ2\n",
    "ìš”ì²­3 â†’       [ì²˜ë¦¬...] â†’ ì‘ë‹µ3\n",
    "```\n",
    "\n",
    "**FDSì—ì„œ ë¹„ë™ê¸°ê°€ ì¤‘ìš”í•œ ì´ìœ :**\n",
    "- ëª¨ë¸ ì¶”ë¡  ì‹œê°„ ë™ì•ˆ ë‹¤ë¥¸ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "- ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ëŸ‰ ì¦ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m     27\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m async_time = time.time() - start\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33më™ê¸° ì²˜ë¦¬ (5ê°œ ìˆœì°¨): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msync_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mì´ˆ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\fds\\Lib\\asyncio\\runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# ğŸ“š async/await ê¸°ë³¸\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "# ë™ê¸° í•¨ìˆ˜\n",
    "def sync_predict(data):\n",
    "    time.sleep(0.1)  # ëª¨ë¸ ì¶”ë¡  ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
    "    return {\"result\": \"fraud\"}\n",
    "\n",
    "# ë¹„ë™ê¸° í•¨ìˆ˜\n",
    "async def async_predict(data):\n",
    "    await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ëŒ€ê¸°\n",
    "    return {\"result\": \"fraud\"}\n",
    "\n",
    "# ë™ê¸° í…ŒìŠ¤íŠ¸\n",
    "start = time.time()\n",
    "for i in range(5):\n",
    "    sync_predict({\"id\": i})\n",
    "sync_time = time.time() - start\n",
    "\n",
    "# ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸\n",
    "async def run_async():\n",
    "    tasks = [async_predict({\"id\": i}) for i in range(5)]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "start = time.time()\n",
    "asyncio.run(run_async())\n",
    "async_time = time.time() - start\n",
    "\n",
    "print(f\"ë™ê¸° ì²˜ë¦¬ (5ê°œ ìˆœì°¨): {sync_time:.2f}ì´ˆ\")\n",
    "print(f\"ë¹„ë™ê¸° ì²˜ë¦¬ (5ê°œ ë™ì‹œ): {async_time:.2f}ì´ˆ\")\n",
    "print(f\"\\nâ†’ ë¹„ë™ê¸°ê°€ {sync_time/async_time:.1f}ë°° ë¹ ë¦„!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. FastAPIì—ì„œ ë¹„ë™ê¸°\n",
    "\n",
    "```python\n",
    "# ë™ê¸° ì—”ë“œí¬ì¸íŠ¸ (def)\n",
    "@app.post(\"/predict\")\n",
    "def predict_sync(request: PredictRequest):\n",
    "    result = model.predict(request)  # ë¸”ë¡œí‚¹\n",
    "    return result\n",
    "\n",
    "# ë¹„ë™ê¸° ì—”ë“œí¬ì¸íŠ¸ (async def)\n",
    "@app.post(\"/predict\")\n",
    "async def predict_async(request: PredictRequest):\n",
    "    result = await model.predict(request)  # ë…¼ë¸”ë¡œí‚¹\n",
    "    return result\n",
    "```\n",
    "\n",
    "**ì£¼ì˜**: CPU ë°”ìš´ë“œ ì‘ì—…(ëª¨ë¸ ì¶”ë¡ )ì€ asyncì˜ ì´ì ì´ ì ìŒ\n",
    "- I/O ë°”ìš´ë“œ (DB ì¡°íšŒ, íŒŒì¼ ì½ê¸°): async íš¨ê³¼ í¼\n",
    "- CPU ë°”ìš´ë“œ (ëª¨ë¸ ì¶”ë¡ ): ë©€í‹°í”„ë¡œì„¸ì‹± í•„ìš”\n",
    "\n",
    "**FDSì—ì„œì˜ ì „ëµ:**\n",
    "```python\n",
    "@app.post(\"/predict\")\n",
    "def predict(request: PredictRequest):  # def ì‚¬ìš©\n",
    "    # XGBoost/LSTM ì¶”ë¡ ì€ CPU ë°”ìš´ë“œ\n",
    "    # FastAPIê°€ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰\n",
    "    return model.predict(request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ëª¨ë¸ ì„œë¹™ íŒ¨í„´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. ëª¨ë¸ ë¡œë”© íŒ¨í„´\n",
    "\n",
    "**ì˜ëª»ëœ ë°©ì‹:**\n",
    "```python\n",
    "@app.post(\"/predict\")\n",
    "def predict(request):\n",
    "    model = load_model()  # âŒ ë§¤ ìš”ì²­ë§ˆë‹¤ ë¡œë”©!\n",
    "    return model.predict(request)\n",
    "```\n",
    "\n",
    "**ì˜¬ë°”ë¥¸ ë°©ì‹:**\n",
    "```python\n",
    "# ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë”©\n",
    "model = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def load_models():\n",
    "    global model\n",
    "    model = load_model()  # âœ… ì‹œì‘ ì‹œ 1íšŒ\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(request):\n",
    "    return model.predict(request)  # ì´ë¯¸ ë¡œë”©ëœ ëª¨ë¸ ì‚¬ìš©\n",
    "```\n",
    "\n",
    "### 4-2. FDS API êµ¬ì¡°\n",
    "\n",
    "```\n",
    "src/api/\n",
    "â”œâ”€â”€ main.py         # FastAPI ì•±, ì—”ë“œí¬ì¸íŠ¸\n",
    "â”œâ”€â”€ schemas.py      # Pydantic ìŠ¤í‚¤ë§ˆ\n",
    "â”œâ”€â”€ predictor.py    # ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡ ë¡œì§\n",
    "â””â”€â”€ __init__.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main.py êµ¬ì¡°:\n",
      "\n",
      "# src/api/main.py\n",
      "from fastapi import FastAPI\n",
      "from .schemas import PredictRequest, PredictResponse\n",
      "from .predictor import FDSPredictor\n",
      "\n",
      "app = FastAPI(title=\"FDS API\")\n",
      "\n",
      "# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ê´€ë¦¬\n",
      "predictor: FDSPredictor = None\n",
      "\n",
      "@app.on_event(\"startup\")\n",
      "def startup():\n",
      "    \"\"\"ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”©\"\"\"\n",
      "    global predictor\n",
      "    predictor = FDSPredictor()\n",
      "    predictor.load_models()\n",
      "\n",
      "@app.get(\"/health\")\n",
      "def health():\n",
      "    \"\"\"í—¬ìŠ¤ ì²´í¬\"\"\"\n",
      "    return {\"status\": \"healthy\", \"model_loaded\": predictor is not None}\n",
      "\n",
      "@app.post(\"/predict\", response_model=PredictResponse)\n",
      "def predict(request: PredictRequest):\n",
      "    \"\"\"ì‚¬ê¸° ì˜ˆì¸¡\"\"\"\n",
      "    return predictor.predict(request)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š FDS API ì „ì²´ êµ¬ì¡° ì˜ˆì‹œ\n",
    "\n",
    "api_main_example = '''\n",
    "# src/api/main.py\n",
    "from fastapi import FastAPI\n",
    "from .schemas import PredictRequest, PredictResponse\n",
    "from .predictor import FDSPredictor\n",
    "\n",
    "app = FastAPI(title=\"FDS API\")\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ê´€ë¦¬\n",
    "predictor: FDSPredictor = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def startup():\n",
    "    \"\"\"ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”©\"\"\"\n",
    "    global predictor\n",
    "    predictor = FDSPredictor()\n",
    "    predictor.load_models()\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    \"\"\"í—¬ìŠ¤ ì²´í¬\"\"\"\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": predictor is not None}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictResponse)\n",
    "def predict(request: PredictRequest):\n",
    "    \"\"\"ì‚¬ê¸° ì˜ˆì¸¡\"\"\"\n",
    "    return predictor.predict(request)\n",
    "'''\n",
    "\n",
    "print(\"main.py êµ¬ì¡°:\")\n",
    "print(api_main_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor.py êµ¬ì¡°:\n",
      "\n",
      "# src/api/predictor.py\n",
      "import joblib\n",
      "import numpy as np\n",
      "from pathlib import Path\n",
      "from .schemas import PredictRequest, PredictResponse, FeatureFactor\n",
      "\n",
      "class FDSPredictor:\n",
      "    \"\"\"FDS ì˜ˆì¸¡ê¸°\"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        self.xgb_model = None\n",
      "        self.explainer = None\n",
      "        self.threshold = 0.5\n",
      "\n",
      "    def load_models(self, models_dir: str = \"models\"):\n",
      "        \"\"\"ëª¨ë¸ ë¡œë”©\"\"\"\n",
      "        models_path = Path(models_dir)\n",
      "\n",
      "        # XGBoost ëª¨ë¸\n",
      "        xgb_info = joblib.load(models_path / \"xgb_model.joblib\")\n",
      "        self.xgb_model = xgb_info[\"model\"]\n",
      "        self.threshold = xgb_info[\"optimal_threshold\"]\n",
      "\n",
      "        # SHAP Explainer\n",
      "        from src.explainer import ShapExplainer\n",
      "        self.explainer = ShapExplainer(self.xgb_model, xgb_info[\"feature_names\"])\n",
      "\n",
      "    def predict(self, request: PredictRequest) -> PredictResponse:\n",
      "        \"\"\"ì˜ˆì¸¡ ë° ì„¤ëª… ìƒì„±\"\"\"\n",
      "        # 1. í”¼ì²˜ ì¶”ì¶œ\n",
      "        features = self._extract_features(request)\n",
      "\n",
      "        # 2. ì˜ˆì¸¡\n",
      "        prob = self.xgb_model.predict_proba(features)[0, 1]\n",
      "        is_fraud = prob >= self.threshold\n",
      "\n",
      "        # 3. SHAP ì„¤ëª…\n",
      "        explanation = self.explainer.create_response(\n",
      "            features, sample_idx=0, threshold=self.threshold\n",
      "        )\n",
      "\n",
      "        return PredictResponse(\n",
      "            transaction_id=request.transaction_id,\n",
      "            fraud_probability=float(prob),\n",
      "            is_fraud=is_fraud,\n",
      "            top_factors=explanation[\"top_factors\"],\n",
      "            explanation_text=explanation[\"explanation_text\"]\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š Predictor í´ë˜ìŠ¤ ì˜ˆì‹œ\n",
    "\n",
    "predictor_example = '''\n",
    "# src/api/predictor.py\n",
    "import joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from .schemas import PredictRequest, PredictResponse, FeatureFactor\n",
    "\n",
    "class FDSPredictor:\n",
    "    \"\"\"FDS ì˜ˆì¸¡ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.xgb_model = None\n",
    "        self.explainer = None\n",
    "        self.threshold = 0.5\n",
    "    \n",
    "    def load_models(self, models_dir: str = \"models\"):\n",
    "        \"\"\"ëª¨ë¸ ë¡œë”©\"\"\"\n",
    "        models_path = Path(models_dir)\n",
    "        \n",
    "        # XGBoost ëª¨ë¸\n",
    "        xgb_info = joblib.load(models_path / \"xgb_model.joblib\")\n",
    "        self.xgb_model = xgb_info[\"model\"]\n",
    "        self.threshold = xgb_info[\"optimal_threshold\"]\n",
    "        \n",
    "        # SHAP Explainer\n",
    "        from src.explainer import ShapExplainer\n",
    "        self.explainer = ShapExplainer(self.xgb_model, xgb_info[\"feature_names\"])\n",
    "    \n",
    "    def predict(self, request: PredictRequest) -> PredictResponse:\n",
    "        \"\"\"ì˜ˆì¸¡ ë° ì„¤ëª… ìƒì„±\"\"\"\n",
    "        # 1. í”¼ì²˜ ì¶”ì¶œ\n",
    "        features = self._extract_features(request)\n",
    "        \n",
    "        # 2. ì˜ˆì¸¡\n",
    "        prob = self.xgb_model.predict_proba(features)[0, 1]\n",
    "        is_fraud = prob >= self.threshold\n",
    "        \n",
    "        # 3. SHAP ì„¤ëª…\n",
    "        explanation = self.explainer.create_response(\n",
    "            features, sample_idx=0, threshold=self.threshold\n",
    "        )\n",
    "        \n",
    "        return PredictResponse(\n",
    "            transaction_id=request.transaction_id,\n",
    "            fraud_probability=float(prob),\n",
    "            is_fraud=is_fraud,\n",
    "            top_factors=explanation[\"top_factors\"],\n",
    "            explanation_text=explanation[\"explanation_text\"]\n",
    "        )\n",
    "'''\n",
    "\n",
    "print(\"predictor.py êµ¬ì¡°:\")\n",
    "print(predictor_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Docker ê¸°ì´ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Dockerë€?\n",
    "\n",
    "**Docker**: ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì»¨í…Œì´ë„ˆë¡œ íŒ¨í‚¤ì§•í•˜ì—¬ ì–´ë””ì„œë“  ì‹¤í–‰\n",
    "\n",
    "#### ì™œ Docker?\n",
    "\n",
    "```\n",
    "âŒ ë¬¸ì œ: \"ë‚´ ì»´í“¨í„°ì—ì„œëŠ” ëëŠ”ë°...\"\n",
    "   - Python ë²„ì „ ì°¨ì´\n",
    "   - íŒ¨í‚¤ì§€ ë²„ì „ ì°¨ì´\n",
    "   - OS ì°¨ì´\n",
    "\n",
    "âœ… Docker: í™˜ê²½ ìì²´ë¥¼ íŒ¨í‚¤ì§•\n",
    "   - ê°œë°œ í™˜ê²½ = ìš´ì˜ í™˜ê²½\n",
    "   - ì–´ë””ì„œë“  ë™ì¼í•˜ê²Œ ì‹¤í–‰\n",
    "```\n",
    "\n",
    "### 5-2. Dockerfile\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# ì½”ë“œ ë³µì‚¬\n",
    "COPY . .\n",
    "\n",
    "# í¬íŠ¸ ë…¸ì¶œ\n",
    "EXPOSE 8000\n",
    "\n",
    "# ì‹¤í–‰ ëª…ë ¹\n",
    "CMD [\"uvicorn\", \"src.api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "### 5-3. Docker Compose\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  fds-api:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes:\n",
    "      - ./models:/app/models\n",
    "    environment:\n",
    "      - MODEL_PATH=/app/models\n",
    "```\n",
    "\n",
    "### 5-4. Docker ëª…ë ¹ì–´\n",
    "\n",
    "```bash\n",
    "# ì´ë¯¸ì§€ ë¹Œë“œ\n",
    "docker build -t fds-api .\n",
    "\n",
    "# ì»¨í…Œì´ë„ˆ ì‹¤í–‰\n",
    "docker run -p 8000:8000 fds-api\n",
    "\n",
    "# docker composeë¡œ ì‹¤í–‰ (ê¶Œì¥)\n",
    "docker compose up -d\n",
    "\n",
    "# ë¡œê·¸ í™•ì¸\n",
    "docker compose logs -f\n",
    "\n",
    "# ì¢…ë£Œ\n",
    "docker compose down\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ë©´ì ‘ Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: \"ì™œ FastAPIë¥¼ ì„ íƒí–ˆë‚˜ìš”?\"\n",
    "\n",
    "> \"ì„¸ ê°€ì§€ ì´ìœ ì…ë‹ˆë‹¤. ì²«ì§¸, ì„±ëŠ¥ì´ Flask ëŒ€ë¹„ 3~5ë°° ë¹ ë¦…ë‹ˆë‹¤.\n",
    "> ë‘˜ì§¸, Pydanticìœ¼ë¡œ ìë™ íƒ€ì… ê²€ì¦ê³¼ ë¬¸ì„œí™”ê°€ ë©ë‹ˆë‹¤.\n",
    "> ì…‹ì§¸, ë¹„ë™ê¸° ì§€ì›ì´ ë„¤ì´í‹°ë¸Œë¼ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ì— ìœ ë¦¬í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "### Q: \"API ì‘ë‹µ ì‹œê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?\"\n",
    "\n",
    "> \"XGBoost ì˜ˆì¸¡ ì•½ 10ms, SHAP ê³„ì‚° ì•½ 100msë¡œ ì´ ì•½ 120msì…ë‹ˆë‹¤.\n",
    "> ëª©í‘œì˜€ë˜ 200ms ì´í•˜ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "> ë°°ì¹˜ ì˜ˆì¸¡ì„ ì§€ì›í•˜ë©´ ì²˜ë¦¬ëŸ‰ì„ ë” ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "### Q: \"ëª¨ë¸ ì—…ë°ì´íŠ¸ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"\n",
    "\n",
    "> \"í˜„ì¬ëŠ” Docker ì´ë¯¸ì§€ ì¬ë¹Œë“œ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "> ëª¨ë¸ íŒŒì¼ì„ ë³¼ë¥¨ ë§ˆìš´íŠ¸í•˜ë©´ ì´ë¯¸ì§€ ì¬ë¹Œë“œ ì—†ì´ êµì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "> Phase 2ì—ì„œ MLflowë¡œ ëª¨ë¸ ë²„ì „ ê´€ë¦¬ë¥¼ ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "### Q: \"ë™ì‹œ ìš”ì²­ì´ ë§ì•„ì§€ë©´ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?\"\n",
    "\n",
    "> \"Uvicorn ì›Œì»¤ ìˆ˜ë¥¼ ëŠ˜ë ¤ì„œ ìŠ¤ì¼€ì¼ì—…í•©ë‹ˆë‹¤.\n",
    "> ë” ë§ì€ ë¶€í•˜ëŠ” Kubernetesë¡œ ìŠ¤ì¼€ì¼ì•„ì›ƒí•©ë‹ˆë‹¤.\n",
    "> í˜„ì¬ ë‹¨ì¼ ì„œë²„ë¡œ ì´ˆë‹¹ 50~100 ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ìµœì¢… ì²´í¬í¬ì¸íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  1-S7 ì™„ë£Œ: FastAPI ê¸°ì´ˆ\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"ë°°ìš´ ê²ƒ:\")\n",
    "print()\n",
    "print(\"1. FastAPI ê¸°ë³¸\")\n",
    "print(\"   - ê³ ì„±ëŠ¥ ì›¹ í”„ë ˆì„ì›Œí¬\")\n",
    "print(\"   - @app.get(), @app.post() ë°ì½”ë ˆì´í„°\")\n",
    "print(\"   - ìë™ Swagger ë¬¸ì„œí™”\")\n",
    "print()\n",
    "print(\"2. Pydantic ìŠ¤í‚¤ë§ˆ\")\n",
    "print(\"   - BaseModelë¡œ ë°ì´í„° ê²€ì¦\")\n",
    "print(\"   - Field()ë¡œ ì œì•½ì¡°ê±´ ì„¤ì •\")\n",
    "print(\"   - ìë™ JSON ë³€í™˜\")\n",
    "print()\n",
    "print(\"3. ë¹„ë™ê¸° ì²˜ë¦¬\")\n",
    "print(\"   - async/await ë¬¸ë²•\")\n",
    "print(\"   - I/O ë°”ìš´ë“œ ì‘ì—…ì— íš¨ê³¼ì \")\n",
    "print(\"   - CPU ë°”ìš´ë“œëŠ” def ì‚¬ìš©\")\n",
    "print()\n",
    "print(\"4. ëª¨ë¸ ì„œë¹™ íŒ¨í„´\")\n",
    "print(\"   - ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”© (@on_event)\")\n",
    "print(\"   - Predictor í´ë˜ìŠ¤ë¡œ ìº¡ìŠí™”\")\n",
    "print(\"   - schemas.py, predictor.py ë¶„ë¦¬\")\n",
    "print()\n",
    "print(\"5. Docker ê¸°ì´ˆ\")\n",
    "print(\"   - Dockerfileë¡œ í™˜ê²½ íŒ¨í‚¤ì§•\")\n",
    "print(\"   - docker compose upìœ¼ë¡œ ì‹¤í–‰\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ë‹¤ìŒ: src/api/ êµ¬í˜„\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
