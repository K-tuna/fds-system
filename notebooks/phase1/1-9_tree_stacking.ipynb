{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-9: 트리 스태킹 (XGBoost + LightGBM + CatBoost)\n",
    "\n",
    "3개 모델 모두 Optuna 튜닝 -> 7개 조합 실험 -> 비용 최소화 기준 최고 선정\n",
    "\n",
    "## 실험 구조\n",
    "\n",
    "### Part 1: Optuna 튜닝 (3개 모델)\n",
    "| 모델 | 튜닝 |\n",
    "|------|------|\n",
    "| 1. XGBoost | Optuna 50 trials (GPU) |\n",
    "| 2. LightGBM | Optuna 50 trials |\n",
    "| 3. CatBoost | Optuna 50 trials (GPU) |\n",
    "\n",
    "### Part 2: 7개 조합 실험\n",
    "| 조합 | 구성 |\n",
    "|------|------|\n",
    "| 1 | XGBoost 단독 |\n",
    "| 2 | LightGBM 단독 |\n",
    "| 3 | CatBoost 단독 |\n",
    "| 12 | XGB + LGBM 스태킹 |\n",
    "| 13 | XGB + Cat 스태킹 |\n",
    "| 23 | LGBM + Cat 스태킹 |\n",
    "| 123 | 3개 모두 스태킹 |\n",
    "\n",
    "### Part 3: 비용 기반 최종 선정\n",
    "- **현업 방식: 거래 금액 기반 비용 함수**\n",
    "- Threshold 최적화 (비용 최소화)\n",
    "- 비용 절감액 비교\n",
    "\n",
    "---\n",
    "\n",
    "## 현업 비용 함수 (Transaction-Level Cost)\n",
    "\n",
    "```\n",
    "총 비용 = FN 비용 + FP 비용\n",
    "\n",
    "FN 비용 = 놓친 사기 거래 금액 합계 (실제 손실)\n",
    "FP 비용 = 오탐 건수 x 관리비용 ($5/건)\n",
    "```\n",
    "\n",
    "**왜 현업 방식인가?**\n",
    "- 고정 비율 (100:1, 27:1)은 모든 사기를 동일하게 취급\n",
    "- 현업에서는 **고액 사기 > 저액 사기** 우선순위\n",
    "- 거래 금액 기반 비용이 더 현실적\n",
    "\n",
    "---\n",
    "\n",
    "## 평가 지표 가이드\n",
    "\n",
    "| 상황 | 지표 | 이유 |\n",
    "|------|------|------|\n",
    "| **모델 비교** | AUPRC | Threshold 무관, 불균형에서 신뢰성 높음 |\n",
    "| **프로덕션 배포** | **비용 최소화** | 현업 = 손실 최소화 |\n",
    "| **결과 보고** | 비용 절감액, Recall | 비즈니스 임팩트 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패키지 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    recall_score, precision_score, f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.base import clone\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 한글 폰트\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"패키지 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (472432, 448)\n",
      "Test shape: (118108, 448)\n",
      "\n",
      "X_train: (377945, 447) (앞쪽 80% - 과거)\n",
      "X_valid: (94487, 447) (뒤쪽 20% - 미래)\n",
      "X_test: (118108, 447) (test_features.csv)\n",
      "사기 비율 - Train: 3.41%\n",
      "scale_pos_weight: 28.31\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 (1-3과 동일)\n",
    "DATA_PROCESSED = Path('../../data/processed')\n",
    "MODEL_DIR = Path('../../models')\n",
    "\n",
    "# Train: train_features.csv\n",
    "# Test: test_features.csv (별도 파일)\n",
    "train_features = pd.read_csv(DATA_PROCESSED / 'train_features.csv')\n",
    "test_features = pd.read_csv(DATA_PROCESSED / 'test_features.csv')\n",
    "\n",
    "print(f\"Train shape: {train_features.shape}\")\n",
    "print(f\"Test shape: {test_features.shape}\")\n",
    "\n",
    "# X, y 분리\n",
    "X_train_full = train_features.drop('isFraud', axis=1)\n",
    "y_train_full = train_features['isFraud']\n",
    "\n",
    "X_test = test_features.drop('isFraud', axis=1)\n",
    "y_test = test_features['isFraud']\n",
    "\n",
    "# Optuna용 train/valid 분할 (시간순 - 1-3과 동일)\n",
    "split_idx = int(len(X_train_full) * 0.8)\n",
    "X_train = X_train_full.iloc[:split_idx]\n",
    "y_train = y_train_full.iloc[:split_idx]\n",
    "X_valid = X_train_full.iloc[split_idx:]\n",
    "y_valid = y_train_full.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nX_train: {X_train.shape} (앞쪽 80% - 과거)\")\n",
    "print(f\"X_valid: {X_valid.shape} (뒤쪽 20% - 미래)\")\n",
    "print(f\"X_test: {X_test.shape} (test_features.csv)\")\n",
    "print(f\"사기 비율 - Train: {y_train.mean():.2%}\")\n",
    "\n",
    "# 불균형 보정 비율\n",
    "scale_pos = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"scale_pos_weight: {scale_pos:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Optuna 튜닝 (3개 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Optuna 튜닝 (50 trials) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.628935: 100%|████████████████████████████████████████████████████| 50/50 [13:20<00:00, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최고 AUPRC: 0.6289\n",
      "소요 시간: 13.3분\n",
      "최적 파라미터: {'n_estimators': 360, 'max_depth': 12, 'learning_rate': 0.13256571358968075, 'min_child_weight': 5, 'subsample': 0.6972817582647092, 'colsample_bytree': 0.6952250555644199, 'gamma': 2.3747426328296894, 'reg_alpha': 0.0020485909809840816, 'reg_lambda': 1.6931365594319552e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Optuna 튜닝 (GPU)\n",
    "print(\"=== XGBoost Optuna 튜닝 (50 trials) ===\")\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10, log=True),\n",
    "        'scale_pos_weight': scale_pos,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "    return average_precision_score(y_valid, y_prob)\n",
    "\n",
    "start = time.time()\n",
    "xgb_study = optuna.create_study(direction='maximize')\n",
    "xgb_study.optimize(xgb_objective, n_trials=50, show_progress_bar=True)\n",
    "xgb_time = time.time() - start\n",
    "\n",
    "print(f\"\\n최고 AUPRC: {xgb_study.best_value:.4f}\")\n",
    "print(f\"소요 시간: {xgb_time/60:.1f}분\")\n",
    "print(f\"최적 파라미터: {xgb_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LightGBM Optuna 튜닝 (50 trials) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.609793: 100%|████████████████████████████████████████████████████| 50/50 [11:28<00:00, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최고 AUPRC: 0.6098\n",
      "소요 시간: 11.5분\n",
      "최적 파라미터: {'n_estimators': 277, 'max_depth': 12, 'learning_rate': 0.0778413725466476, 'num_leaves': 80, 'min_child_samples': 57, 'subsample': 0.930588919495799, 'colsample_bytree': 0.7522279065031027, 'reg_alpha': 0.0006085814112324581, 'reg_lambda': 0.07030709170684916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Optuna 튜닝\n",
    "print(\"=== LightGBM Optuna 튜닝 (50 trials) ===\")\n",
    "\n",
    "def lgbm_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10, log=True),\n",
    "        'scale_pos_weight': scale_pos,\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "    return average_precision_score(y_valid, y_prob)\n",
    "\n",
    "start = time.time()\n",
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(lgbm_objective, n_trials=50, show_progress_bar=True)\n",
    "lgbm_time = time.time() - start\n",
    "\n",
    "print(f\"\\n최고 AUPRC: {lgbm_study.best_value:.4f}\")\n",
    "print(f\"소요 시간: {lgbm_time/60:.1f}분\")\n",
    "print(f\"최적 파라미터: {lgbm_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CatBoost Optuna 튜닝 (50 trials) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.615785: 100%|████████████████████████████████████████████████████| 50/50 [11:42<00:00, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최고 AUPRC: 0.6158\n",
      "소요 시간: 11.7분\n",
      "최적 파라미터: {'iterations': 499, 'depth': 10, 'learning_rate': 0.09130642360023586, 'l2_leaf_reg': 9.990752490658366, 'border_count': 111, 'bagging_temperature': 0.5780473676308638}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Optuna 튜닝 (GPU)\n",
    "print(\"=== CatBoost Optuna 튜닝 (50 trials) ===\")\n",
    "\n",
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'scale_pos_weight': scale_pos,\n",
    "        'random_state': 42,\n",
    "        'verbose': 0,\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_valid)[:, 1]\n",
    "    return average_precision_score(y_valid, y_prob)\n",
    "\n",
    "start = time.time()\n",
    "cat_study = optuna.create_study(direction='maximize')\n",
    "cat_study.optimize(cat_objective, n_trials=50, show_progress_bar=True)\n",
    "cat_time = time.time() - start\n",
    "\n",
    "print(f\"\\n최고 AUPRC: {cat_study.best_value:.4f}\")\n",
    "print(f\"소요 시간: {cat_time/60:.1f}분\")\n",
    "print(f\"최적 파라미터: {cat_study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  Part 1 완료: 3개 모델 Optuna 튜닝\n",
      "============================================================\n",
      "\n",
      "  XGBoost  AUPRC: 0.6289 (13.3분)\n",
      "  LightGBM AUPRC: 0.6098 (11.5분)\n",
      "  CatBoost AUPRC: 0.6158 (11.7분)\n",
      "\n",
      "  총 소요 시간: 36.5분\n"
     ]
    }
   ],
   "source": [
    "# Part 1 결과 요약\n",
    "print(\"=\" * 60)\n",
    "print(\"  Part 1 완료: 3개 모델 Optuna 튜닝\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  XGBoost  AUPRC: {xgb_study.best_value:.4f} ({xgb_time/60:.1f}분)\")\n",
    "print(f\"  LightGBM AUPRC: {lgbm_study.best_value:.4f} ({lgbm_time/60:.1f}분)\")\n",
    "print(f\"  CatBoost AUPRC: {cat_study.best_value:.4f} ({cat_time/60:.1f}분)\")\n",
    "print(f\"\\n  총 소요 시간: {(xgb_time + lgbm_time + cat_time)/60:.1f}분\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: 7개 조합 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튜닝된 모델 생성 완료!\n",
      "  - XGB\n",
      "  - LGBM\n",
      "  - Cat\n"
     ]
    }
   ],
   "source": [
    "# 튜닝된 모델 생성\n",
    "xgb_best_params = xgb_study.best_params.copy()\n",
    "xgb_best_params.update({\n",
    "    'scale_pos_weight': scale_pos,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'random_state': 42,\n",
    "    'verbosity': 0\n",
    "})\n",
    "\n",
    "lgbm_best_params = lgbm_study.best_params.copy()\n",
    "lgbm_best_params.update({\n",
    "    'scale_pos_weight': scale_pos,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "})\n",
    "\n",
    "cat_best_params = cat_study.best_params.copy()\n",
    "cat_best_params.update({\n",
    "    'scale_pos_weight': scale_pos,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0,\n",
    "    'task_type': 'GPU'\n",
    "})\n",
    "\n",
    "tuned_models = {\n",
    "    'XGB': XGBClassifier(**xgb_best_params),\n",
    "    'LGBM': LGBMClassifier(**lgbm_best_params),\n",
    "    'Cat': CatBoostClassifier(**cat_best_params)\n",
    "}\n",
    "\n",
    "print(\"튜닝된 모델 생성 완료!\")\n",
    "for name in tuned_models:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF 함수 정의 완료! (TimeSeriesSplit - 시간순)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def get_oof_predictions(model, X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Out-of-Fold 예측 생성 (시간순 분할 - Data Leakage 방지)\n",
    "    \"\"\"\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_tr = X.iloc[train_idx] if hasattr(X, 'iloc') else X[train_idx]\n",
    "        X_val = X.iloc[val_idx] if hasattr(X, 'iloc') else X[val_idx]\n",
    "        y_tr = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx]\n",
    "        \n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tr, y_tr)\n",
    "        oof_preds[val_idx] = model_clone.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    return oof_preds\n",
    "\n",
    "print(\"OOF 함수 정의 완료! (TimeSeriesSplit - 시간순)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OOF 예측 생성 ===\n",
      "\n",
      "XGB OOF 생성 중...\n",
      "  OOF 완료 (60.9s)\n",
      "  Test 예측 완료\n",
      "\n",
      "LGBM OOF 생성 중...\n",
      "  OOF 완료 (57.4s)\n",
      "  Test 예측 완료\n",
      "\n",
      "Cat OOF 생성 중...\n",
      "  OOF 완료 (96.8s)\n",
      "  Test 예측 완료\n",
      "\n",
      "=== OOF 생성 완료 ===\n"
     ]
    }
   ],
   "source": [
    "# 전체 train 데이터로 OOF 생성\n",
    "print(\"=== OOF 예측 생성 ===\")\n",
    "\n",
    "oof_preds = {}\n",
    "test_preds = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    print(f\"\\n{name} OOF 생성 중...\")\n",
    "    start = time.time()\n",
    "    oof_preds[name] = get_oof_predictions(model, X_train_full, y_train_full)\n",
    "    print(f\"  OOF 완료 ({time.time()-start:.1f}s)\")\n",
    "    \n",
    "    # 전체 데이터로 재학습 후 테스트 예측\n",
    "    model_final = clone(model)\n",
    "    model_final.fit(X_train_full, y_train_full)\n",
    "    test_preds[name] = model_final.predict_proba(X_test)[:, 1]\n",
    "    trained_models[name] = model_final\n",
    "    print(f\"  Test 예측 완료\")\n",
    "\n",
    "print(\"\\n=== OOF 생성 완료 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1_XGB ===\n",
      "  AUPRC: 0.5867\n",
      "  AUC:   0.9085\n",
      "\n",
      "=== 2_LGBM ===\n",
      "  AUPRC: 0.5521\n",
      "  AUC:   0.9094\n",
      "\n",
      "=== 3_Cat ===\n",
      "  AUPRC: 0.5670\n",
      "  AUC:   0.9110\n",
      "\n",
      "=== 12_XGB_LGBM ===\n",
      "  Meta 가중치: {'XGB': np.float64(3.692), 'LGBM': np.float64(3.163)}\n",
      "  AUPRC: 0.5930\n",
      "  AUC:   0.9167\n",
      "\n",
      "=== 13_XGB_Cat ===\n",
      "  Meta 가중치: {'XGB': np.float64(3.473), 'Cat': np.float64(3.591)}\n",
      "  AUPRC: 0.5937\n",
      "  AUC:   0.9168\n",
      "\n",
      "=== 23_LGBM_Cat ===\n",
      "  Meta 가중치: {'LGBM': np.float64(2.625), 'Cat': np.float64(3.831)}\n",
      "  AUPRC: 0.5741\n",
      "  AUC:   0.9176\n",
      "\n",
      "=== 123_All ===\n",
      "  Meta 가중치: {'XGB': np.float64(2.788), 'LGBM': np.float64(2.041), 'Cat': np.float64(2.176)}\n",
      "  AUPRC: 0.5957\n",
      "  AUC:   0.9205\n",
      "\n",
      "=== 7개 조합 실험 완료 ===\n"
     ]
    }
   ],
   "source": [
    "# 7개 조합 정의 및 실험\n",
    "combinations = {\n",
    "    '1_XGB': ['XGB'],\n",
    "    '2_LGBM': ['LGBM'],\n",
    "    '3_Cat': ['Cat'],\n",
    "    '12_XGB_LGBM': ['XGB', 'LGBM'],\n",
    "    '13_XGB_Cat': ['XGB', 'Cat'],\n",
    "    '23_LGBM_Cat': ['LGBM', 'Cat'],\n",
    "    '123_All': ['XGB', 'LGBM', 'Cat']\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for combo_name, models_list in combinations.items():\n",
    "    print(f\"\\n=== {combo_name} ===\")\n",
    "    \n",
    "    if len(models_list) == 1:\n",
    "        # 단독 모델\n",
    "        model_name = models_list[0]\n",
    "        y_prob_test = test_preds[model_name]\n",
    "    else:\n",
    "        # 스태킹\n",
    "        # OOF로 메타 피처 생성\n",
    "        meta_train = np.column_stack([oof_preds[m] for m in models_list])\n",
    "        meta_test = np.column_stack([test_preds[m] for m in models_list])\n",
    "        \n",
    "        # 메타 러너 학습\n",
    "        meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        meta_model.fit(meta_train, y_train_full)\n",
    "        y_prob_test = meta_model.predict_proba(meta_test)[:, 1]\n",
    "        \n",
    "        # 메타 가중치 출력\n",
    "        print(f\"  Meta 가중치: {dict(zip(models_list, meta_model.coef_[0].round(3)))}\")\n",
    "    \n",
    "    # 평가\n",
    "    auprc = average_precision_score(y_test, y_prob_test)\n",
    "    auc = roc_auc_score(y_test, y_prob_test)\n",
    "    \n",
    "    results[combo_name] = {\n",
    "        'models': models_list,\n",
    "        'y_prob': y_prob_test,\n",
    "        'AUPRC': auprc,\n",
    "        'AUC': auc\n",
    "    }\n",
    "    \n",
    "    print(f\"  AUPRC: {auprc:.4f}\")\n",
    "    print(f\"  AUC:   {auc:.4f}\")\n",
    "\n",
    "print(\"\\n=== 7개 조합 실험 완료 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 7개 조합 AUPRC 비교 ===\n",
      "      Combo       Models    AUPRC      AUC\n",
      "    123_All XGB+LGBM+Cat 0.595665 0.920501\n",
      " 13_XGB_Cat      XGB+Cat 0.593709 0.916836\n",
      "12_XGB_LGBM     XGB+LGBM 0.593035 0.916690\n",
      "      1_XGB          XGB 0.586659 0.908524\n",
      "23_LGBM_Cat     LGBM+Cat 0.574127 0.917622\n",
      "      3_Cat          Cat 0.567036 0.911028\n",
      "     2_LGBM         LGBM 0.552067 0.909433\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7개 조합 AUPRC 비교\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Combo': name, 'Models': '+'.join(r['models']), 'AUPRC': r['AUPRC'], 'AUC': r['AUC']}\n",
    "    for name, r in results.items()\n",
    "]).sort_values('AUPRC', ascending=False)\n",
    "\n",
    "print(\"=== 7개 조합 AUPRC 비교 ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(comparison_df)))\n",
    "bars = ax.barh(comparison_df['Combo'], comparison_df['AUPRC'], color=colors)\n",
    "ax.set_xlabel('AUPRC')\n",
    "ax.set_title('7개 조합 AUPRC 비교')\n",
    "\n",
    "for bar, val in zip(bars, comparison_df['AUPRC']):\n",
    "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: 최종 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  AUPRC 기준 최고 조합: 123_All\n",
      "============================================================\n",
      "\n",
      "  모델 구성: XGB + LGBM + Cat\n",
      "  AUPRC: 0.5957\n",
      "  AUC:   0.9205\n"
     ]
    }
   ],
   "source": [
    "# AUPRC 기준 최고 조합 선정\n",
    "best_combo = comparison_df.iloc[0]['Combo']\n",
    "best_result = results[best_combo]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"  AUPRC 기준 최고 조합: {best_combo}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  모델 구성: {' + '.join(best_result['models'])}\")\n",
    "print(f\"  AUPRC: {best_result['AUPRC']:.4f}\")\n",
    "print(f\"  AUC:   {best_result['AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (모델 없이 전부 정상 예측 시) ===\n",
      "  총 사기 금액 손실: $609,934\n",
      "  (이것이 FDS 없을 때 손실)\n",
      "\n",
      "======================================================================\n",
      "  현업 Threshold 최적화 방식 2가지\n",
      "======================================================================\n",
      "  1. 비용 함수: FN = 놓친 사기 금액, FP = 오탐 x $1\n",
      "  2. FP Rate 제한: FP Rate 5% 이하에서 최대 Recall (현업 표준)\n"
     ]
    }
   ],
   "source": [
    "# 현업 비용 함수 (Transaction-Level Cost)\n",
    "def calculate_business_cost(y_true, y_pred, amounts, admin_cost):\n",
    "    \"\"\"\n",
    "    현업 비용 함수\n",
    "    - FN: 놓친 사기 거래 금액 합계 (실제 손실)\n",
    "    - FP: 오탐 건수 x 관리비용 (검토 인건비)\n",
    "    \n",
    "    Args:\n",
    "        y_true: 실제 레이블\n",
    "        y_pred: 예측 레이블\n",
    "        amounts: 거래 금액 (TransactionAmt)\n",
    "        admin_cost: 오탐 1건당 관리비용 ($5 기본)\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    amounts = np.array(amounts)\n",
    "    \n",
    "    fn_mask = (y_true == 1) & (y_pred == 0)  # 놓친 사기\n",
    "    fp_mask = (y_true == 0) & (y_pred == 1)  # 오탐\n",
    "    \n",
    "    fn_cost = amounts[fn_mask].sum()  # 실제 사기 금액\n",
    "    fp_cost = fp_mask.sum() * admin_cost  # 관리비용\n",
    "    \n",
    "    return fn_cost + fp_cost, fn_cost, fp_cost\n",
    "\n",
    "\n",
    "def find_optimal_threshold_business(y_true, y_prob, amounts, admin_cost):\n",
    "    \"\"\"비즈니스 비용 최소화 threshold 탐색\"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_cost = float('inf')\n",
    "    best_details = {}\n",
    "    \n",
    "    thresholds = np.linspace(0, 1, 1001)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        total_cost, fn_cost, fp_cost = calculate_business_cost(\n",
    "            y_true, y_pred, amounts, admin_cost\n",
    "        )\n",
    "        \n",
    "        if total_cost < best_cost:\n",
    "            best_cost = total_cost\n",
    "            best_threshold = threshold\n",
    "            best_details = {'fn_cost': fn_cost, 'fp_cost': fp_cost}\n",
    "    \n",
    "    return best_threshold, best_cost, best_details\n",
    "\n",
    "\n",
    "def find_threshold_by_fpr(y_true, y_prob, max_fpr=0.05):\n",
    "    \"\"\"\n",
    "    FP Rate 제한 기반 threshold 탐색 (현업 표준)\n",
    "    \n",
    "    현업 방식: \"FP Rate X% 이하로 유지하면서 최대 Recall 달성\"\n",
    "    - 운영팀이 처리 가능한 FP Rate를 제한\n",
    "    - 그 안에서 Recall 최대화\n",
    "    \n",
    "    Args:\n",
    "        y_true: 실제 레이블\n",
    "        y_prob: 예측 확률\n",
    "        max_fpr: 최대 허용 FP Rate (기본 5%)\n",
    "    \n",
    "    Returns:\n",
    "        threshold, actual_fpr, recall\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    \n",
    "    # FPR <= max_fpr 인 지점 중 최대 TPR (Recall)\n",
    "    valid_idx = np.where(fpr <= max_fpr)[0]\n",
    "    \n",
    "    if len(valid_idx) == 0:\n",
    "        # max_fpr 이하가 없으면 가장 낮은 FPR 선택\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = valid_idx[-1]  # FPR <= max_fpr 중 가장 높은 TPR\n",
    "    \n",
    "    return thresholds[idx], fpr[idx], tpr[idx]\n",
    "\n",
    "\n",
    "# TransactionAmt 추출\n",
    "amounts_test = X_test['TransactionAmt'].values\n",
    "\n",
    "# Baseline: 모든 거래를 정상으로 예측 시 손실 (= 전체 사기 금액)\n",
    "baseline_cost = amounts_test[y_test == 1].sum()\n",
    "print(f\"=== Baseline (모델 없이 전부 정상 예측 시) ===\")\n",
    "print(f\"  총 사기 금액 손실: ${baseline_cost:,.0f}\")\n",
    "print(f\"  (이것이 FDS 없을 때 손실)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"  현업 Threshold 최적화 방식 2가지\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  1. 비용 함수: FN = 놓친 사기 금액, FP = 오탐 x $1\")\n",
    "print(\"  2. FP Rate 제한: FP Rate 5% 이하에서 최대 Recall (현업 표준)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  방법 1: 비용 함수 기반 Threshold 최적화\n",
      "======================================================================\n",
      "  FN = 놓친 사기 금액, FP = 오탐 x $1\n",
      "\n",
      "1_XGB:\n",
      "  Threshold: 0.002\n",
      "  비용: $86,759 (FN: $33,627, FP: $53,132)\n",
      "  절감액: $523,176 (85.8%)\n",
      "  Recall: 0.9456, FP Rate: 46.6%\n",
      "\n",
      "2_LGBM:\n",
      "  Threshold: 0.057\n",
      "  비용: $76,299 (FN: $17,129, FP: $59,170)\n",
      "  절감액: $533,635 (87.5%)\n",
      "  Recall: 0.9572, FP Rate: 51.9%\n",
      "\n",
      "3_Cat:\n",
      "  Threshold: 0.029\n",
      "  비용: $81,339 (FN: $25,454, FP: $55,885)\n",
      "  절감액: $528,595 (86.7%)\n",
      "  Recall: 0.9542, FP Rate: 49.0%\n",
      "\n",
      "12_XGB_LGBM:\n",
      "  Threshold: 0.016\n",
      "  비용: $75,300 (FN: $22,192, FP: $53,108)\n",
      "  절감액: $534,634 (87.7%)\n",
      "  Recall: 0.9530, FP Rate: 46.6%\n",
      "\n",
      "13_XGB_Cat:\n",
      "  Threshold: 0.016\n",
      "  비용: $81,509 (FN: $23,199, FP: $58,310)\n",
      "  절감액: $528,425 (86.6%)\n",
      "  Recall: 0.9599, FP Rate: 51.1%\n",
      "\n",
      "23_LGBM_Cat:\n",
      "  Threshold: 0.017\n",
      "  비용: $78,218 (FN: $31,244, FP: $46,974)\n",
      "  절감액: $531,716 (87.2%)\n",
      "  Recall: 0.9437, FP Rate: 41.2%\n",
      "\n",
      "123_All:\n",
      "  Threshold: 0.017\n",
      "  비용: $77,075 (FN: $30,562, FP: $46,513)\n",
      "  절감액: $532,859 (87.4%)\n",
      "  Recall: 0.9454, FP Rate: 40.8%\n",
      "\n",
      "================================================================================\n",
      "  비용 순위 (낮을수록 좋음)\n",
      "================================================================================\n",
      "      Combo  total_cost  savings_pct   recall      fpr  threshold\n",
      "12_XGB_LGBM   75300.431    87.654338 0.953002 0.465680      0.016\n",
      "     2_LGBM   76299.301    87.490571 0.957185 0.518835      0.057\n",
      "    123_All   77075.225    87.363357 0.945374 0.407851      0.017\n",
      "23_LGBM_Cat   78218.448    87.175923 0.943652 0.411894      0.017\n",
      "      3_Cat   81339.121    86.664282 0.954232 0.490030      0.029\n",
      " 13_XGB_Cat   81508.878    86.636450 0.959892 0.511294      0.016\n",
      "      1_XGB   86758.775    85.775719 0.945620 0.465890      0.002\n"
     ]
    }
   ],
   "source": [
    "# 방법 1: 비용 함수 기반 최적화\n",
    "print(\"=\" * 70)\n",
    "print(\"  방법 1: 비용 함수 기반 Threshold 최적화\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  FN = 놓친 사기 금액, FP = 오탐 x $1\\n\")\n",
    "\n",
    "cost_results = {}  # dict로 저장 (나중에 비교용)\n",
    "admin_cost = 1\n",
    "\n",
    "for combo_name, r in results.items():\n",
    "    threshold, total_cost, details = find_optimal_threshold_business(\n",
    "        y_test, r['y_prob'], amounts_test, admin_cost\n",
    "    )\n",
    "    \n",
    "    y_pred = (r['y_prob'] >= threshold).astype(int)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # FP Rate 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    # 비용 절감액\n",
    "    savings = baseline_cost - total_cost\n",
    "    savings_pct = (savings / baseline_cost) * 100\n",
    "    \n",
    "    cost_results[combo_name] = {\n",
    "        'threshold': threshold,\n",
    "        'total_cost': total_cost,\n",
    "        'fn_cost': details['fn_cost'],\n",
    "        'fp_cost': details['fp_cost'],\n",
    "        'savings': savings,\n",
    "        'savings_pct': savings_pct,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'fpr': fpr\n",
    "    }\n",
    "    \n",
    "    print(f\"{combo_name}:\")\n",
    "    print(f\"  Threshold: {threshold:.3f}\")\n",
    "    print(f\"  비용: ${total_cost:,.0f} (FN: ${details['fn_cost']:,.0f}, FP: ${details['fp_cost']:,.0f})\")\n",
    "    print(f\"  절감액: ${savings:,.0f} ({savings_pct:.1f}%)\")\n",
    "    print(f\"  Recall: {recall:.4f}, FP Rate: {fpr:.1%}\")\n",
    "    print()\n",
    "\n",
    "# 비용 순위 출력\n",
    "cost_df = pd.DataFrame([\n",
    "    {'Combo': k, **v} for k, v in cost_results.items()\n",
    "]).sort_values('total_cost')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"  비용 순위 (낮을수록 좋음)\")\n",
    "print(\"=\" * 80)\n",
    "print(cost_df[['Combo', 'total_cost', 'savings_pct', 'recall', 'fpr', 'threshold']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  방법 2: FP Rate 제한 기반 Threshold 최적화 (현업 표준)\n",
      "======================================================================\n",
      "  FP Rate 5% 이하에서 최대 Recall 달성\n",
      "\n",
      "1_XGB:\n",
      "  Threshold: 0.083\n",
      "  FP Rate:   4.99% (제한: 5%)\n",
      "  Recall:    67.67%\n",
      "  비용:      $217,972\n",
      "\n",
      "2_LGBM:\n",
      "  Threshold: 0.517\n",
      "  FP Rate:   5.00% (제한: 5%)\n",
      "  Recall:    66.95%\n",
      "  비용:      $209,594\n",
      "\n",
      "3_Cat:\n",
      "  Threshold: 0.370\n",
      "  FP Rate:   4.98% (제한: 5%)\n",
      "  Recall:    68.11%\n",
      "  비용:      $210,132\n",
      "\n",
      "12_XGB_LGBM:\n",
      "  Threshold: 0.080\n",
      "  FP Rate:   5.00% (제한: 5%)\n",
      "  Recall:    69.78%\n",
      "  비용:      $194,524\n",
      "\n",
      "13_XGB_Cat:\n",
      "  Threshold: 0.067\n",
      "  FP Rate:   4.98% (제한: 5%)\n",
      "  Recall:    69.96%\n",
      "  비용:      $196,765\n",
      "\n",
      "23_LGBM_Cat:\n",
      "  Threshold: 0.138\n",
      "  FP Rate:   4.99% (제한: 5%)\n",
      "  Recall:    69.73%\n",
      "  비용:      $193,556\n",
      "\n",
      "123_All:\n",
      "  Threshold: 0.085\n",
      "  FP Rate:   4.99% (제한: 5%)\n",
      "  Recall:    70.96%\n",
      "  비용:      $188,376\n",
      "\n",
      "================================================================================\n",
      "  FP Rate 5% 제한 하 Recall 순위\n",
      "================================================================================\n",
      "      Combo   recall      fpr  threshold  total_cost\n",
      "    123_All 0.709646 0.049946   0.084997  188376.156\n",
      " 13_XGB_Cat 0.699557 0.049814   0.067168  196764.577\n",
      "12_XGB_LGBM 0.697835 0.049989   0.079737  194523.704\n",
      "23_LGBM_Cat 0.697343 0.049893   0.137966  193555.922\n",
      "      3_Cat 0.681102 0.049788   0.369631  210132.294\n",
      "      1_XGB 0.676673 0.049937   0.082576  217972.484\n",
      "     2_LGBM 0.669537 0.049972   0.516901  209594.404\n"
     ]
    }
   ],
   "source": [
    "# 방법 2: FP Rate 제한 기반 최적화 (현업 표준)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"  방법 2: FP Rate 제한 기반 Threshold 최적화 (현업 표준)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  FP Rate 5% 이하에서 최대 Recall 달성\\n\")\n",
    "\n",
    "fpr_results = {}\n",
    "max_fpr = 0.05  # 5% 제한\n",
    "\n",
    "for combo_name, r in results.items():\n",
    "    threshold, actual_fpr, recall = find_threshold_by_fpr(\n",
    "        y_test, r['y_prob'], max_fpr=max_fpr\n",
    "    )\n",
    "    \n",
    "    y_pred = (r['y_prob'] >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # 비용 계산 (비교용)\n",
    "    total_cost, fn_cost, fp_cost = calculate_business_cost(\n",
    "        y_test, y_pred, amounts_test, admin_cost=1\n",
    "    )\n",
    "    \n",
    "    fpr_results[combo_name] = {\n",
    "        'threshold': threshold,\n",
    "        'fpr': actual_fpr,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'total_cost': total_cost,\n",
    "        'fn_cost': fn_cost,\n",
    "        'fp_cost': fp_cost\n",
    "    }\n",
    "    \n",
    "    print(f\"{combo_name}:\")\n",
    "    print(f\"  Threshold: {threshold:.3f}\")\n",
    "    print(f\"  FP Rate:   {actual_fpr:.2%} (제한: {max_fpr:.0%})\")\n",
    "    print(f\"  Recall:    {recall:.2%}\")\n",
    "    print(f\"  비용:      ${total_cost:,.0f}\")\n",
    "    print()\n",
    "\n",
    "# Recall 순위 출력\n",
    "fpr_df = pd.DataFrame([\n",
    "    {'Combo': k, **v} for k, v in fpr_results.items()\n",
    "]).sort_values('recall', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"  FP Rate 5% 제한 하 Recall 순위\")\n",
    "print(\"=\" * 80)\n",
    "print(fpr_df[['Combo', 'recall', 'fpr', 'threshold', 'total_cost']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "  비용 함수 vs FP Rate 제한 비교\n",
      "================================================================================\n",
      "         조합 비용함수_Threshold FPR제한_Threshold 비용함수_Recall FPR제한_Recall 비용함수_FPR FPR제한_FPR\n",
      "      1_XGB          0.002           0.083       94.6%        67.7%    46.6%      5.0%\n",
      "     2_LGBM          0.057           0.517       95.7%        67.0%    51.9%      5.0%\n",
      "      3_Cat          0.029           0.370       95.4%        68.1%    49.0%      5.0%\n",
      "12_XGB_LGBM          0.016           0.080       95.3%        69.8%    46.6%      5.0%\n",
      " 13_XGB_Cat          0.016           0.067       96.0%        70.0%    51.1%      5.0%\n",
      "23_LGBM_Cat          0.017           0.138       94.4%        69.7%    41.2%      5.0%\n",
      "    123_All          0.017           0.085       94.5%        71.0%    40.8%      5.0%\n",
      "\n",
      "================================================================================\n",
      "  결론\n",
      "================================================================================\n",
      "\n",
      "[비용 함수 방식]\n",
      "- Threshold: ~0.02 (매우 낮음)\n",
      "- Recall: ~95% (높음)\n",
      "- FP Rate: ~45% (매우 높음) → 운영 불가\n",
      "\n",
      "[FP Rate 제한 방식]\n",
      "- Threshold: ~0.08 (123_All 기준)\n",
      "- Recall: ~71% (모델의 실제 능력치)\n",
      "- FP Rate: 5% (운영 가능)\n",
      "\n",
      "⚠️ 단일 Threshold의 한계:\n",
      "- FP Rate 5% 제한 시 Recall 71%만 가능\n",
      "- 현업에서는 \"계층형 대응\"으로 해결 (1-7 참조)\n",
      "  → Block(95%+) / Hold(70-95%) / Verify(30-70%) / Pass(<30%)\n",
      "- API에서 risk_level로 4단계 반환 중\n",
      "\n",
      "→ 비용 함수: 연구/실험용 (비즈니스 비용 산정)\n",
      "→ FP Rate 제한: 모델 능력치 확인용\n",
      "→ 프로덕션: 계층형 대응 (1-7 방식)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 방법 1 vs 방법 2 비교\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"  비용 함수 vs FP Rate 제한 비교\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for combo_name in results.keys():\n",
    "    comparison_data.append({\n",
    "        '조합': combo_name,\n",
    "        '비용함수_Threshold': f\"{cost_results[combo_name]['threshold']:.3f}\",\n",
    "        'FPR제한_Threshold': f\"{fpr_results[combo_name]['threshold']:.3f}\",\n",
    "        '비용함수_Recall': f\"{cost_results[combo_name]['recall']:.1%}\",\n",
    "        'FPR제한_Recall': f\"{fpr_results[combo_name]['recall']:.1%}\",\n",
    "        '비용함수_FPR': f\"{cost_results[combo_name]['fpr']:.1%}\",\n",
    "        'FPR제한_FPR': f\"{fpr_results[combo_name]['fpr']:.1%}\",\n",
    "    })\n",
    "\n",
    "comparison_df2 = pd.DataFrame(comparison_data)\n",
    "print(comparison_df2.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"  결론\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "[비용 함수 방식]\n",
    "- Threshold: ~0.02 (매우 낮음)\n",
    "- Recall: ~95% (높음)\n",
    "- FP Rate: ~45% (매우 높음) → 운영 불가\n",
    "\n",
    "[FP Rate 제한 방식]\n",
    "- Threshold: ~0.08 (123_All 기준)\n",
    "- Recall: ~71% (모델의 실제 능력치)\n",
    "- FP Rate: 5% (운영 가능)\n",
    "\n",
    "⚠️ 단일 Threshold의 한계:\n",
    "- FP Rate 5% 제한 시 Recall 71%만 가능\n",
    "- 현업에서는 \"계층형 대응\"으로 해결 (1-7 참조)\n",
    "  → Block(95%+) / Hold(70-95%) / Verify(30-70%) / Pass(<30%)\n",
    "- API에서 risk_level로 4단계 반환 중\n",
    "\n",
    "→ 비용 함수: 연구/실험용 (비즈니스 비용 산정)\n",
    "→ FP Rate 제한: 모델 능력치 확인용\n",
    "→ 프로덕션: 계층형 대응 (1-7 방식)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  최종 선정: 123_All\n",
      "======================================================================\n",
      "\n",
      "[FP Rate 제한 방식 - 현업 표준]\n",
      "  Threshold: 0.085\n",
      "  Recall:    71.0%\n",
      "  FP Rate:   5.0%\n",
      "\n",
      "[비용 함수 방식 - 참고]\n",
      "  Threshold: 0.017\n",
      "  Recall:    94.5%\n",
      "  비용:      $77,075\n",
      "\n",
      "[공통 지표]\n",
      "  AUPRC: 0.5957\n",
      "  AUC:   0.9205\n",
      "\n",
      "저장: ..\\..\\models\\stacking_xgb_tuned.joblib\n",
      "\n",
      "저장: ..\\..\\models\\stacking_lgbm_tuned.joblib\n",
      "\n",
      "저장: ..\\..\\models\\stacking_cat_tuned.joblib\n",
      "저장: ..\\..\\models\\stacking_config.joblib\n"
     ]
    }
   ],
   "source": [
    "# 최종 선정 및 저장\n",
    "# FP Rate 제한 방식 기준 최고 조합 선정 (현업 표준)\n",
    "best_fpr_row = fpr_df.iloc[0]  # Recall 최고\n",
    "final_choice = best_fpr_row['Combo']\n",
    "final_threshold_fpr = best_fpr_row['threshold']\n",
    "final_recall_fpr = best_fpr_row['recall']\n",
    "final_fpr = best_fpr_row['fpr']\n",
    "\n",
    "# 비용 함수 방식 결과도 참조\n",
    "final_threshold_cost = cost_results[final_choice]['threshold']\n",
    "final_recall_cost = cost_results[final_choice]['recall']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"  최종 선정: {final_choice}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n[FP Rate 제한 방식 - 현업 표준]\")\n",
    "print(f\"  Threshold: {final_threshold_fpr:.3f}\")\n",
    "print(f\"  Recall:    {final_recall_fpr:.1%}\")\n",
    "print(f\"  FP Rate:   {final_fpr:.1%}\")\n",
    "\n",
    "print(f\"\\n[비용 함수 방식 - 참고]\")\n",
    "print(f\"  Threshold: {final_threshold_cost:.3f}\")\n",
    "print(f\"  Recall:    {final_recall_cost:.1%}\")\n",
    "print(f\"  비용:      ${cost_results[final_choice]['total_cost']:,.0f}\")\n",
    "\n",
    "print(f\"\\n[공통 지표]\")\n",
    "print(f\"  AUPRC: {results[final_choice]['AUPRC']:.4f}\")\n",
    "print(f\"  AUC:   {results[final_choice]['AUC']:.4f}\")\n",
    "\n",
    "# 모델 설정 저장 (두 방식 모두 포함)\n",
    "model_config = {\n",
    "    'combo': final_choice,\n",
    "    'models': results[final_choice]['models'],\n",
    "    'threshold_methods': {\n",
    "        'fpr_constraint': {\n",
    "            'threshold': final_threshold_fpr,\n",
    "            'max_fpr': 0.05,\n",
    "            'recall': final_recall_fpr,\n",
    "            'description': 'FP Rate 5% 제한 (현업 표준)'\n",
    "        },\n",
    "        'cost_function': {\n",
    "            'threshold': final_threshold_cost,\n",
    "            'admin_cost': 1,\n",
    "            'recall': final_recall_cost,\n",
    "            'description': '비용 함수 기반 (FN=금액, FP=$1)'\n",
    "        }\n",
    "    },\n",
    "    'metrics': {\n",
    "        'AUPRC': results[final_choice]['AUPRC'],\n",
    "        'AUC': results[final_choice]['AUC']\n",
    "    },\n",
    "    'optuna_params': {\n",
    "        'XGB': xgb_study.best_params,\n",
    "        'LGBM': lgbm_study.best_params,\n",
    "        'Cat': cat_study.best_params\n",
    "    }\n",
    "}\n",
    "\n",
    "# 개별 모델 저장\n",
    "for name, model in trained_models.items():\n",
    "    joblib.dump(model, MODEL_DIR / f'stacking_{name.lower()}_tuned.joblib')\n",
    "    print(f\"\\n저장: {MODEL_DIR / f'stacking_{name.lower()}_tuned.joblib'}\")\n",
    "\n",
    "# 설정 저장\n",
    "joblib.dump(model_config, MODEL_DIR / 'stacking_config.joblib')\n",
    "print(f\"저장: {MODEL_DIR / 'stacking_config.joblib'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  메타 모델 저장 (API 서빙용)\n",
      "======================================================================\n",
      "\n",
      "메타 모델 가중치:\n",
      "  XGB:  2.7875\n",
      "  LGBM: 2.0405\n",
      "  Cat:  2.1757\n",
      "  Intercept: -4.3621\n",
      "\n",
      "저장: ..\\..\\models\\stacking_meta_model.joblib\n",
      "저장: ..\\..\\models\\stacking_feature_names.joblib\n",
      "\n",
      "======================================================================\n",
      "  API 서빙에 필요한 파일 목록\n",
      "======================================================================\n",
      "\n",
      "models/\n",
      "├── stacking_xgb_tuned.joblib      # XGBoost 모델\n",
      "├── stacking_lgbm_tuned.joblib     # LightGBM 모델\n",
      "├── stacking_cat_tuned.joblib      # CatBoost 모델\n",
      "├── stacking_meta_model.joblib     # 메타 러너 (LogisticRegression)\n",
      "├── stacking_feature_names.joblib  # 피처 이름 목록\n",
      "└── stacking_config.joblib         # 설정 (threshold 등)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메타 모델 저장 (API 서빙용)\n",
    "# 123_All 조합의 메타 모델 재생성 및 저장\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  메타 모델 저장 (API 서빙용)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# OOF 예측으로 메타 피처 생성\n",
    "meta_train_123 = np.column_stack([\n",
    "    oof_preds['XGB'],\n",
    "    oof_preds['LGBM'],\n",
    "    oof_preds['Cat']\n",
    "])\n",
    "\n",
    "# 메타 러너 학습\n",
    "meta_model_123 = LogisticRegression(max_iter=1000, random_state=42)\n",
    "meta_model_123.fit(meta_train_123, y_train_full)\n",
    "\n",
    "print(f\"\\n메타 모델 가중치:\")\n",
    "print(f\"  XGB:  {meta_model_123.coef_[0][0]:.4f}\")\n",
    "print(f\"  LGBM: {meta_model_123.coef_[0][1]:.4f}\")\n",
    "print(f\"  Cat:  {meta_model_123.coef_[0][2]:.4f}\")\n",
    "print(f\"  Intercept: {meta_model_123.intercept_[0]:.4f}\")\n",
    "\n",
    "# 메타 모델 저장\n",
    "joblib.dump(meta_model_123, MODEL_DIR / 'stacking_meta_model.joblib')\n",
    "print(f\"\\n저장: {MODEL_DIR / 'stacking_meta_model.joblib'}\")\n",
    "\n",
    "# 피처 이름도 저장 (API에서 필요)\n",
    "feature_names = list(X_train_full.columns)\n",
    "joblib.dump(feature_names, MODEL_DIR / 'stacking_feature_names.joblib')\n",
    "print(f\"저장: {MODEL_DIR / 'stacking_feature_names.joblib'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"  API 서빙에 필요한 파일 목록\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "models/\n",
    "├── stacking_xgb_tuned.joblib      # XGBoost 모델\n",
    "├── stacking_lgbm_tuned.joblib     # LightGBM 모델\n",
    "├── stacking_cat_tuned.joblib      # CatBoost 모델\n",
    "├── stacking_meta_model.joblib     # 메타 러너 (LogisticRegression)\n",
    "├── stacking_feature_names.joblib  # 피처 이름 목록\n",
    "└── stacking_config.joblib         # 설정 (threshold 등)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 결론 및 면접 Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  1-9 완료: 트리 스태킹 + 현업 Threshold 최적화\n",
      "======================================================================\n",
      "\n",
      "[Part 1] 3개 모델 Optuna 튜닝\n",
      "  XGBoost:  AUPRC 0.6289\n",
      "  LightGBM: AUPRC 0.6098\n",
      "  CatBoost: AUPRC 0.6158\n",
      "\n",
      "[Part 2] 7개 조합 실험\n",
      "  1, 2, 3, 12, 13, 23, 123\n",
      "\n",
      "[Part 3] Threshold 최적화 (2가지 방식)\n",
      "  방법 1: 비용 함수 (FN=금액, FP=$1) → 연구용\n",
      "  방법 2: FP Rate 제한 (max 5%) → 현업 표준\n",
      "\n",
      "======================================================================\n",
      "  최종 선정: 123_All\n",
      "======================================================================\n",
      "\n",
      "  [현업 방식 - FP Rate 5% 제한]\n",
      "    Threshold: 0.085\n",
      "    Recall:    71.0%\n",
      "    FP Rate:   5.0%\n",
      "\n",
      "  [AUPRC: 0.5957]\n",
      "\n",
      "저장된 파일:\n",
      "  models/stacking_xgb_tuned.joblib\n",
      "  models/stacking_lgbm_tuned.joblib\n",
      "  models/stacking_cat_tuned.joblib\n",
      "  models/stacking_config.joblib\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"  1-9 완료: 트리 스태킹 + 현업 Threshold 최적화\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"[Part 1] 3개 모델 Optuna 튜닝\")\n",
    "print(f\"  XGBoost:  AUPRC {xgb_study.best_value:.4f}\")\n",
    "print(f\"  LightGBM: AUPRC {lgbm_study.best_value:.4f}\")\n",
    "print(f\"  CatBoost: AUPRC {cat_study.best_value:.4f}\")\n",
    "print()\n",
    "print(\"[Part 2] 7개 조합 실험\")\n",
    "print(\"  1, 2, 3, 12, 13, 23, 123\")\n",
    "print()\n",
    "print(\"[Part 3] Threshold 최적화 (2가지 방식)\")\n",
    "print(\"  방법 1: 비용 함수 (FN=금액, FP=$1) → 연구용\")\n",
    "print(\"  방법 2: FP Rate 제한 (max 5%) → 현업 표준\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"  최종 선정: {final_choice}\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"  [현업 방식 - FP Rate 5% 제한]\")\n",
    "print(f\"    Threshold: {final_threshold_fpr:.3f}\")\n",
    "print(f\"    Recall:    {final_recall_fpr:.1%}\")\n",
    "print(f\"    FP Rate:   {final_fpr:.1%}\")\n",
    "print()\n",
    "print(f\"  [AUPRC: {results[final_choice]['AUPRC']:.4f}]\")\n",
    "print()\n",
    "print(\"저장된 파일:\")\n",
    "print(\"  models/stacking_xgb_tuned.joblib\")\n",
    "print(\"  models/stacking_lgbm_tuned.joblib\")\n",
    "print(\"  models/stacking_cat_tuned.joblib\")\n",
    "print(\"  models/stacking_config.joblib\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 면접 Q&A\n",
    "\n",
    "**Q: \"Threshold를 어떻게 결정했나요?\"**\n",
    "\n",
    "> \"두 가지 방식을 비교했습니다:\n",
    "> 1. **비용 함수**: FN = 놓친 사기 금액, FP = $1 → Threshold 0.02, Recall 95%\n",
    "> 2. **FP Rate 제한**: 5% 이하 유지 → Threshold 0.08, Recall 71%\n",
    ">\n",
    "> 비용 함수는 FP Rate 45%로 운영 불가능.\n",
    "> FP Rate 5% 제한 시 Recall 71%가 모델의 실제 능력치입니다.\n",
    ">\n",
    "> **현업에서는 계층형 대응으로 해결합니다:**\n",
    "> - Block (95%+): 자동 차단\n",
    "> - Hold (70-95%): 담당자 검토\n",
    "> - Verify (30-70%): 추가 인증\n",
    "> - Pass (<30%): 승인\n",
    ">\n",
    "> 이 프로젝트에서도 1-7 API에서 4단계 risk_level을 반환합니다.\"\n",
    "\n",
    "**Q: \"FP Rate 5%에서 Recall 71%밖에 안 나오는데, 현업에서 어떻게 쓰나요?\"**\n",
    "\n",
    "> \"단일 Threshold의 한계입니다. 현업에서는 **계층형 대응**으로 해결합니다:\n",
    "> - 사기 확률 95%+ → Block (자동 차단)\n",
    "> - 사기 확률 70-95% → Hold (담당자 검토)\n",
    "> - 사기 확률 30-70% → Verify (추가 인증)\n",
    "> - 사기 확률 <30% → Pass (승인)\n",
    ">\n",
    "> 단일 threshold는 연구용이고, 프로덕션은 계층형입니다.\n",
    "> 이 프로젝트의 1-7 API도 이미 4단계 risk_level을 구현했습니다.\"\n",
    "\n",
    "**Q: \"비용 함수를 어떻게 설계했나요?\"**\n",
    "\n",
    "> \"고정 비율(100:1, 27:1) 대신 **거래 금액 기반 가변 비용**을 사용했습니다.\n",
    "> - FN 비용 = 놓친 사기 거래의 실제 금액\n",
    "> - FP 비용 = 오탐 건당 관리비용 ($1~5 가정)\n",
    ">\n",
    "> 이렇게 하면 고액 사기를 놓치는 것이 저액 사기보다 더 큰 페널티를 받습니다.\"\n",
    "\n",
    "**Q: \"현업에서 FP Rate는 보통 몇 %로 설정하나요?\"**\n",
    "\n",
    "> \"산업별로 다릅니다:\n",
    "> - 신용카드: 1~3% (고객 경험 중시)\n",
    "> - 은행 송금: 3~5% (보수적)\n",
    "> - 이커머스: 5~10% (사기 비율 높음)\n",
    ">\n",
    "> 이 프로젝트에서는 5%로 설정했습니다.\"\n",
    "\n",
    "**Q: \"왜 3개 모델을 모두 튜닝했나요?\"**\n",
    "\n",
    "> \"현업에서 스태킹할 때는 각 base 모델을 개별 튜닝합니다.\n",
    "> 기본 파라미터는 데이터 특성을 반영하지 못해서, 스태킹해도 효과가 제한적입니다.\n",
    "> 튜닝된 모델들을 스태킹해야 진정한 다양성(diversity)을 얻을 수 있습니다.\"\n",
    "\n",
    "**Q: \"왜 7개 조합을 다 비교했나요?\"**\n",
    "\n",
    "> \"3개 모델 스태킹이 항상 최고는 아닙니다.\n",
    "> 2개 모델 스태킹이 더 좋을 수도 있고, 단독 모델이 오히려 나을 수도 있습니다.\n",
    "> 모든 조합을 실험해서 데이터에 맞는 최적 구성을 찾는게 정석입니다.\"\n",
    "\n",
    "**Q: \"AUPRC vs 비용 최소화 vs FP Rate 제한, 언제 뭘 쓰나요?\"**\n",
    "\n",
    "> \"- **AUPRC**: 모델 '능력' 비교 (threshold 무관)\n",
    "> - **비용 최소화**: 연구/실험용 (비즈니스 비용 산정 시)\n",
    "> - **FP Rate 제한**: 모델 능력치 확인용\n",
    "> - **프로덕션**: 계층형 대응 (단일 threshold 사용 안함)\n",
    ">\n",
    "> 이 프로젝트에서는 AUPRC로 모델 비교 후, 1-7에서 계층형 대응을 구현했습니다.\"\n",
    "\n",
    "**Q: \"sklearn StackingClassifier를 왜 안 썼나요?\"**\n",
    "\n",
    "> \"sklearn 1.6+에서 CatBoost가 `__sklearn_tags__` 미구현으로 호환 안 됩니다.\n",
    "> 현업에서도 수동 OOF 스태킹을 많이 씁니다. 더 유연하고 커스텀하기 쉽습니다.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
